#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
EXTRACTEUR PDF - RelevÃ©s Bancaires (API PDF Native)
====================================================
Parse bank statements and extract individual accounting events using Claude's native PDF support.

Date: 06/11/2025
Auteur: Module Phase 1 - Accounting Events

RESPONSABILITÃ‰S:
----------------
1. Lecture et parsing de PDF de relevÃ©s bancaires
2. Extraction des opÃ©rations individuelles via Claude API PDF native
3. Normalisation des donnÃ©es (dates, montants, libellÃ©s)
4. DÃ©tection du type d'opÃ©ration (DEBIT/CREDIT)
5. PrÃ©paration des donnÃ©es pour crÃ©ation d'Ã©vÃ©nements

FORMATS SUPPORTÃ‰S:
-----------------
- RelevÃ©s bancaires LCL (format standard)
- Factures comptables
- Distributions SCPI
- Confirmations d'achat ETF/Actions
- Apports d'associÃ©s

WORKFLOW SIMPLIFIÃ‰:
------------------
1. Lecture du PDF (binaire)
2. Encode base64
3. Envoi direct Ã  Claude API (type="document")
4. Analyse et extraction en une seule passe
5. Retour des Ã©vÃ©nements structurÃ©s
"""

import os
import json
import base64
import gc  # Garbage collector pour libÃ©ration mÃ©moire explicite
from datetime import datetime
from typing import Dict, List, Optional
from anthropic import Anthropic
from rapprocheur_operations import RapprocheurOperations

# Configuration
ANTHROPIC_API_KEY = os.getenv('ANTHROPIC_API_KEY')


class ExtracteurPDF:
    """
    Extracteur d'Ã©vÃ©nements comptables depuis PDF via Claude API native
    """

    def __init__(self, pdf_path: str, email_metadata: Optional[Dict] = None):
        """
        Initialise l'extracteur

        Args:
            pdf_path: Chemin vers le fichier PDF
            email_metadata: MÃ©tadonnÃ©es de l'email source (optionnel)
                - email_id: ID de l'email
                - email_from: ExpÃ©diteur
                - email_date: Date de l'email
                - email_subject: Sujet de l'email
        """
        self.pdf_path = pdf_path
        self.email_metadata = email_metadata or {}
        self.client = Anthropic(api_key=ANTHROPIC_API_KEY) if ANTHROPIC_API_KEY else None
        self._analyse_cache = None  # Cache pour Ã©viter double analyse du document
        self._justificatifs_metadata = {}  # MÃ©tadonnÃ©es des justificatifs (Phase 2)

    def _lire_pdf_base64(self) -> str:
        """
        Lit le PDF et retourne son contenu encodÃ© en base64

        Returns:
            Contenu du PDF en base64
        """
        with open(self.pdf_path, 'rb') as f:
            pdf_data = f.read()
        return base64.standard_b64encode(pdf_data).decode('utf-8')

    def _deduplicater_operations(self, operations: List[Dict]) -> List[Dict]:
        """
        DÃ©duplication dÃ©terministe basÃ©e sur double fingerprint + score de qualitÃ©

        STRATÃ‰GIE (FIX 12/11/2025):
        1. Calculer DEUX fingerprints pour chaque opÃ©ration:
           - Fingerprint complet: date + libellÃ© + montant + type
           - Fingerprint simplifiÃ©: date + montant + type (SANS libellÃ©)
        2. Grouper d'abord par fingerprint complet (doublons exacts)
        3. Puis grouper par fingerprint simplifiÃ© (doublons SCPI/Apports)
        4. Dans chaque groupe, garder celle avec le score qualitÃ© le plus Ã©levÃ©

        FIX DOUBLONS SCPI/APPORTS (12/11/2025):
        - MÃªme opÃ©ration apparaÃ®t 2 fois: relevÃ© bancaire + avis d'opÃ©ration
        - LibellÃ©s diffÃ©rents â†’ fingerprint complet diffÃ©rent
        - Mais mÃªme date + montant + type â†’ fingerprint simplifiÃ© identique
        - Solution: Utiliser les DEUX fingerprints pour dÃ©tecter tous les doublons

        Args:
            operations: Liste des opÃ©rations extraites

        Returns:
            Liste dÃ©dupliquÃ©e (garde version la plus dÃ©taillÃ©e de chaque groupe)
        """
        # TEST EXTRACTION COMPLÃˆTE: DÃ©sactiver dÃ©duplication temporairement
        print(f"âš ï¸  TEST: DÃ©duplication DÃ‰SACTIVÃ‰E - Garde toutes les {len(operations)} opÃ©rations")
        return operations

        if len(operations) == 0:
            return operations

        try:
            from detection_doublons import DetecteurDoublons
            from collections import defaultdict

            # Ã‰TAPE 1: Grouper par fingerprint COMPLET (doublons exacts)
            groupes_complets = defaultdict(list)

            for op in operations:
                fingerprint = DetecteurDoublons.calculer_fingerprint(op)
                score_qualite = DetecteurDoublons.calculer_score_qualite(op)
                groupes_complets[fingerprint].append((op, score_qualite))

            # Garder la meilleure de chaque groupe (fingerprint complet)
            operations_apres_dedupe1 = []
            doublons_exacts = 0

            for fingerprint, ops_avec_score in groupes_complets.items():
                if len(ops_avec_score) > 1:
                    ops_avec_score.sort(key=lambda x: x[1], reverse=True)
                    doublons_exacts += len(ops_avec_score) - 1

                operations_apres_dedupe1.append((ops_avec_score[0][0], ops_avec_score[0][1]))

            # Ã‰TAPE 2: Grouper par fingerprint SIMPLIFIÃ‰ (doublons SCPI/Apports)
            groupes_simplifies = defaultdict(list)

            for op, score in operations_apres_dedupe1:
                fingerprint_simple = DetecteurDoublons.calculer_fingerprint_simplifie(op)
                groupes_simplifies[fingerprint_simple].append((op, score))

            # Garder la meilleure de chaque groupe (fingerprint simplifiÃ©)
            operations_finales = []
            doublons_scpi_apports = 0

            for fingerprint_simple, ops_avec_score in groupes_simplifies.items():
                if len(ops_avec_score) > 1:
                    # Trier par score dÃ©croissant
                    ops_avec_score.sort(key=lambda x: x[1], reverse=True)
                    doublons_scpi_apports += len(ops_avec_score) - 1

                    # Debug: Afficher les doublons SCPI/Apports dÃ©tectÃ©s
                    meilleure = ops_avec_score[0][0]
                    if doublons_scpi_apports <= 5:  # Limiter l'affichage
                        print(f"ğŸ” Doublon SCPI/Apport: {meilleure['date_operation']} - {meilleure['montant']}â‚¬")
                        print(f"   GardÃ©: {meilleure['libelle'][:70]}... (score: {ops_avec_score[0][1]})")
                        for op_dup, score_dup in ops_avec_score[1:]:
                            print(f"   SupprimÃ©: {op_dup['libelle'][:70]}... (score: {score_dup})")

                # Garder la meilleure (ou la seule)
                operations_finales.append(ops_avec_score[0][0])

            total_doublons = doublons_exacts + doublons_scpi_apports
            if total_doublons > 0:
                print(f"âœ… DÃ©duplication: {len(operations)} â†’ {len(operations_finales)} opÃ©rations")
                print(f"   â€¢ Doublons exacts: {doublons_exacts}")
                print(f"   â€¢ Doublons SCPI/Apports: {doublons_scpi_apports}")
            else:
                print(f"âœ… DÃ©duplication: {len(operations)} opÃ©rations (aucun doublon dÃ©tectÃ©)")

            return operations_finales

        except Exception as e:
            print(f"âš ï¸  Erreur dÃ©duplication dÃ©terministe (on garde toutes les opÃ©rations): {e}")
            import traceback
            traceback.print_exc()
            return operations

    def analyser_document(self) -> Dict:
        """
        Analyse le document pour extraire le type, la pÃ©riode ET les sections
        Utilise l'API PDF native de Claude

        Returns:
            Dictionnaire avec:
                - type_document: str (ex: "releve_bancaire", "facture_scpi", etc.)
                - date_debut: str (format YYYY-MM-DD)
                - date_fin: str (format YYYY-MM-DD)
                - description: str (rÃ©sumÃ©)
                - sections: dict (ex: {"releves": [1, 20], "avis_vm": [21, 41]})
        """
        if not self.client:
            raise ValueError("ANTHROPIC_API_KEY non dÃ©finie")

        if not os.path.exists(self.pdf_path):
            raise FileNotFoundError(f"PDF non trouvÃ©: {self.pdf_path}")

        print(f"ğŸ” Analyse du document: {os.path.basename(self.pdf_path)}")

        try:
            # Lire le PDF en base64
            pdf_base64 = self._lire_pdf_base64()

            # Analyser avec Claude (API PDF native)
            response = self.client.messages.create(
                model="claude-haiku-4-5-20251001",
                max_tokens=1000,
                messages=[{
                    "role": "user",
                    "content": [
                        {
                            "type": "document",
                            "source": {
                                "type": "base64",
                                "media_type": "application/pdf",
                                "data": pdf_base64
                            }
                        },
                        {
                            "type": "text",
                            "text": """Analyse ce document comptable PDF et extrais les informations suivantes:

1. TYPE DE DOCUMENT PRINCIPAL:
   - releve_bancaire
   - facture_scpi
   - tableau_amortissement
   - facture_comptable
   - autre

2. PÃ‰RIODE COUVERTE (pour les relevÃ©s bancaires):
   - Date de PREMIÃˆRE opÃ©ration
   - Date de DERNIÃˆRE opÃ©ration
   - Analyse TOUTES les pages

3. SECTIONS DU DOCUMENT:
   CRITIQUE: Identifie les diffÃ©rentes sections du PDF par numÃ©ro de page.

   Pour chaque type de contenu, indique:
   - page_debut: premiÃ¨re page de cette section
   - page_fin: derniÃ¨re page de cette section

   Types de sections Ã  dÃ©tecter:
   - "releves_bancaires": Pages avec colonnes (Date | LibellÃ© | DÃ©bit | CrÃ©dit)
   - "avis_operations_vm": Avis d'achat/vente de titres (ETF, actions)
   - "tableaux_amortissement": Tableaux de prÃªt avec Ã©chÃ©ances
   - "factures": Factures diverses (comptable, LEI, etc.)
   - "autres": Autre contenu

4. DESCRIPTION:
   - Courte description du contenu global (1 phrase)

EXEMPLE DE RÃ‰PONSE:
{
  "type_document": "releve_bancaire",
  "date_debut": "2023-12-05",
  "date_fin": "2024-10-04",
  "description": "RelevÃ©s LCL + avis d'opÃ©ration sur valeurs mobiliÃ¨res",
  "sections": {
    "releves_bancaires": {"page_debut": 1, "page_fin": 20},
    "avis_operations_vm": {"page_debut": 21, "page_fin": 38},
    "factures": {"page_debut": 39, "page_fin": 41}
  }
}

NE retourne QUE le JSON, sans texte avant ou aprÃ¨s."""
                        }
                    ]
                }]
            )

            response_text = response.content[0].text

            # Nettoyer la rÃ©ponse
            json_text = response_text.strip()
            if json_text.startswith('```json'):
                json_text = json_text[7:]
            if json_text.startswith('```'):
                json_text = json_text[3:]
            if json_text.endswith('```'):
                json_text = json_text[:-3]
            json_text = json_text.strip()

            # Parser le JSON
            data = json.loads(json_text)

            print(f"   Type: {data.get('type_document', 'inconnu')}")
            print(f"   PÃ©riode: {data.get('date_debut', '?')} â†’ {data.get('date_fin', '?')}")
            print(f"   Description: {data.get('description', '')}")

            # Afficher les sections dÃ©tectÃ©es
            sections = data.get('sections', {})
            if sections:
                print(f"   ğŸ“‘ Sections dÃ©tectÃ©es:")
                for section_type, pages in sections.items():
                    if isinstance(pages, dict):
                        print(f"      â€¢ {section_type}: pages {pages.get('page_debut', '?')}-{pages.get('page_fin', '?')}")

            # Mettre en cache pour Ã©viter double analyse
            self._analyse_cache = data

            return data

        except json.JSONDecodeError as e:
            print(f"âš ï¸  Erreur parsing JSON: {e}")
            print(f"   RÃ©ponse: {response_text[:200]}...")
            return {
                'type_document': 'inconnu',
                'date_debut': None,
                'date_fin': None,
                'description': 'Analyse Ã©chouÃ©e'
            }
        except Exception as e:
            print(f"âš ï¸  Erreur analyse document: {e}")
            import traceback
            traceback.print_exc()
            return {
                'type_document': 'inconnu',
                'date_debut': None,
                'date_fin': None,
                'description': f'Erreur: {str(e)}'
            }

    def _extraire_operations_chunk(self, pdf_base64: str, chunk_num: int, total_chunks: int,
                                   section_type: str = 'releves_bancaires',
                                   pages_chunk: str = '') -> List[Dict]:
        """
        Extrait les opÃ©rations d'un chunk de PDF avec un prompt adaptÃ© au type de section

        Args:
            pdf_base64: PDF encodÃ© en base64
            chunk_num: NumÃ©ro du chunk (1-based)
            total_chunks: Nombre total de chunks
            section_type: Type de section ('releves_bancaires', 'factures_comptables', etc.)
            pages_chunk: Pages du chunk (ex: "21-25") pour affichage

        Returns:
            Liste des opÃ©rations extraites
        """
        if chunk_num > 1:
            print(f"ğŸ”„ Chunk {chunk_num}/{total_chunks} (pages {pages_chunk}, {section_type}): Envoi Ã  Claude...")
        else:
            print(f"ğŸ”„ Envoi du PDF Ã  Claude pour extraction... ({total_chunks} lot{'s' if total_chunks > 1 else ''})")

        # Construire le prompt selon le type de section
        prompt_text = self._construire_prompt_extraction(section_type)

        response = self.client.messages.create(
            model="claude-haiku-4-5-20251001",
            max_tokens=64000,
            messages=[{
                "role": "user",
                "content": [
                    {
                        "type": "document",
                        "source": {
                            "type": "base64",
                            "media_type": "application/pdf",
                            "data": pdf_base64
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt_text
                    }
                ]
            }]
        )

        # DEBUG: VÃ©rifier pourquoi l'extraction s'arrÃªte
        stop_reason = response.stop_reason
        response_text = response.content[0].text

        print(f"   ğŸ” DEBUG Chunk {chunk_num}: stop_reason={stop_reason}, taille_rÃ©ponse={len(response_text)} chars")

        # Nettoyer la rÃ©ponse
        json_text = response_text.strip()
        if json_text.startswith('```json'):
            json_text = json_text[7:]
        if json_text.startswith('```'):
            json_text = json_text[3:]
        if json_text.endswith('```'):
            json_text = json_text[:-3]
        json_text = json_text.strip()

        # Parser le JSON - extraction robuste
        try:
            data = json.loads(json_text)
            operations = data.get('operations', [])
        except json.JSONDecodeError as e:
            # Tentative d'extraction robuste : trouver le JSON valide
            # Claude ajoute parfois du texte explicatif aprÃ¨s le JSON
            try:
                # Trouver le premier { et essayer de parser jusqu'Ã  trouver un JSON valide
                start_idx = json_text.find('{')
                if start_idx == -1:
                    raise ValueError("Pas de JSON trouvÃ© dans la rÃ©ponse")

                # Essayer de trouver la fin du JSON en comptant les accolades
                brace_count = 0
                end_idx = start_idx
                for i in range(start_idx, len(json_text)):
                    if json_text[i] == '{':
                        brace_count += 1
                    elif json_text[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end_idx = i + 1
                            break

                # Extraire et parser le JSON
                clean_json = json_text[start_idx:end_idx]
                data = json.loads(clean_json)
                operations = data.get('operations', [])
                print(f"   âœ“ JSON extrait avec succÃ¨s aprÃ¨s nettoyage (texte supplÃ©mentaire ignorÃ©)")
            except Exception as e2:
                print(f"   âš ï¸  ERREUR JSON Chunk {chunk_num}: {e}")
                print(f"   âš ï¸  Extraction robuste Ã©chouÃ©e: {e2}")
                print(f"   ğŸ“„ DÃ©but JSON: {json_text[:200]}...")
                print(f"   ğŸ“„ Fin JSON: ...{json_text[-200:]}")
                return []

        # VÃ©rifier si la rÃ©ponse semble tronquÃ©e
        if stop_reason == 'max_tokens' and len(operations) < 10:
            print(f"   âš ï¸  TRONCATURE DÃ‰TECTÃ‰E Chunk {chunk_num}: stop_reason=max_tokens mais seulement {len(operations)} opÃ©rations")

        # Afficher le nombre d'opÃ©rations extraites pour TOUS les chunks
        if chunk_num > 1:
            print(f"   âœ“ Chunk {chunk_num}/{total_chunks}: {len(operations)} opÃ©rations extraites")
        else:
            print(f"   âœ“ Chunk {chunk_num}/{total_chunks}: {len(operations)} opÃ©rations extraites")

        # TRAÃ‡ABILITÃ‰: Afficher dÃ©tails des opÃ©rations extraites (pour debug)
        if operations:
            print(f"   ğŸ“‹ DÃ©tails extractions chunk {chunk_num}:")
            for op in operations:
                date = op.get('date_operation', 'N/A')
                montant = op.get('montant', 0)
                libelle_court = op.get('libelle', '')[:60] + ('...' if len(op.get('libelle', '')) > 60 else '')
                print(f"      â€¢ {date} - {montant}â‚¬ - {libelle_court}")

        return operations

    def _extraire_pdf_complet(self, sections_ordonnees: List[Dict]) -> List[Dict]:
        """
        Extrait le PDF COMPLET en UN SEUL appel API avec un prompt intelligent

        Cette approche est utilisÃ©e pour les PDFs â‰¤ 50 pages.
        Avantages : Plus rapide, meilleur contexte global, pas de doublons entre chunks

        Args:
            sections_ordonnees: Liste des sections dÃ©tectÃ©es avec leurs pages

        Returns:
            Liste des opÃ©rations extraites
        """
        # Lire le PDF en base64
        pdf_base64 = self._lire_pdf_base64()

        # Construire le prompt unifiÃ© dÃ©crivant toutes les sections
        prompt = self._construire_prompt_unifie(sections_ordonnees)

        print(f"ğŸ”„ Envoi du PDF complet Ã  Claude pour extraction...")

        response = self.client.messages.create(
            model="claude-haiku-4-5-20251001",
            max_tokens=64000,
            messages=[{
                "role": "user",
                "content": [
                    {
                        "type": "document",
                        "source": {
                            "type": "base64",
                            "media_type": "application/pdf",
                            "data": pdf_base64
                        }
                    },
                    {
                        "type": "text",
                        "text": prompt
                    }
                ]
            }]
        )

        # Parser la rÃ©ponse JSON
        response_text = response.content[0].text.strip()

        # Nettoyer la rÃ©ponse (enlever markdown si prÃ©sent)
        json_text = response_text
        if json_text.startswith('```json'):
            json_text = json_text[7:]
        if json_text.startswith('```'):
            json_text = json_text[3:]
        if json_text.endswith('```'):
            json_text = json_text[:-3]
        json_text = json_text.strip()

        # Parser le JSON avec gestion d'erreur robuste
        try:
            data = json.loads(json_text)
            operations = data.get('operations', [])
        except json.JSONDecodeError as e:
            # Extraction robuste
            try:
                start_idx = json_text.find('{')
                if start_idx == -1:
                    raise ValueError("Pas de JSON trouvÃ©")

                brace_count = 0
                end_idx = start_idx
                for i in range(start_idx, len(json_text)):
                    if json_text[i] == '{':
                        brace_count += 1
                    elif json_text[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            end_idx = i + 1
                            break

                clean_json = json_text[start_idx:end_idx]
                data = json.loads(clean_json)
                operations = data.get('operations', [])
                print(f"   âœ“ JSON extrait avec succÃ¨s aprÃ¨s nettoyage")
            except Exception as e2:
                print(f"   âš ï¸  ERREUR JSON: {e}")
                print(f"   ğŸ“„ DÃ©but: {json_text[:200]}...")
                return []

        print(f"   âœ“ {len(operations)} opÃ©rations extraites")

        # Afficher les dÃ©tails pour debug
        if operations:
            print(f"   ğŸ“‹ DÃ©tails extractions:")
            for op in operations[:5]:  # Afficher les 5 premiÃ¨res
                date = op.get('date_operation', '?')
                montant = op.get('montant', 0)
                libelle = op.get('libelle', '')[:60]
                print(f"      â€¢ {date} - {montant}â‚¬ - {libelle}")
            if len(operations) > 5:
                print(f"      ... et {len(operations) - 5} autres opÃ©rations")

        return operations

    def _construire_prompt_unifie(self, sections_ordonnees: List[Dict]) -> str:
        """
        Construit un prompt UNIFIÃ‰ dÃ©crivant toutes les sections du PDF

        Args:
            sections_ordonnees: Liste des sections dÃ©tectÃ©es

        Returns:
            Prompt texte pour extraction globale
        """
        # Description de base
        prompt_parts = [
            "Tu es un extracteur d'opÃ©rations comptables pour la SCI Soeurise.",
            "",
            "CONTEXTE SCI:",
            "- SCI NON soumise Ã  TVA",
            "- DÃ©tails HT/TVA inutiles pour comptabilitÃ©",
            "- Seuls les montants TTC comptent",
            "",
            "CE DOCUMENT CONTIENT PLUSIEURS TYPES DE PAGES:"
        ]

        # Ajouter la description de chaque section
        for section in sections_ordonnees:
            nom = section['nom']
            debut = section['page_debut']
            fin = section['page_fin']

            if nom == 'releves_bancaires':
                prompt_parts.append(f"\nPages {debut}-{fin}: RELEVÃ‰S BANCAIRES")
                prompt_parts.append("â†’ Extrait TOUTES les opÃ©rations du relevÃ©")
                prompt_parts.append("â†’ Date, libellÃ© complet, montant, type (DEBIT/CREDIT)")

            elif nom == 'factures_comptables':
                prompt_parts.append(f"\nPages {debut}-{fin}: FACTURES COMPTABLES")
                prompt_parts.append("â†’ Pour CHAQUE facture: UNIQUEMENT le Total TTC")
                prompt_parts.append("â†’ Ignore les lignes de dÃ©tail (HT, TVA, Honoraires, Provision)")
                prompt_parts.append("â†’ UNE facture = UNE opÃ©ration (le Total TTC)")
                prompt_parts.append("â†’ Date = date de paiement (pas date facture)")

            elif nom == 'bulletins_dividendes_scpi':
                prompt_parts.append(f"\nPages {debut}-{fin}: BULLETINS SCPI")
                prompt_parts.append("â†’ UN bulletin = UNE opÃ©ration (mÃªme s'il fait plusieurs pages)")
                prompt_parts.append("â†’ Montant total annoncÃ© uniquement")
                prompt_parts.append("â†’ Si un bulletin continue sur 2 pages, NE L'EXTRAIT QU'UNE FOIS")

            elif nom == 'avis_operations_vm':
                prompt_parts.append(f"\nPages {debut}-{fin}: AVIS OPÃ‰RATIONS VALEURS MOBILIÃˆRES")
                prompt_parts.append("â†’ DÃ©tails complets: ISIN, quantitÃ©, prix, montant total")
                prompt_parts.append("â†’ LibellÃ©: 'Achat/Vente' + quantitÃ© + nom titre + ISIN + prix")

            elif nom == 'factures_autres':
                prompt_parts.append(f"\nPages {debut}-{fin}: AUTRES FACTURES (LEI, etc.)")
                prompt_parts.append("â†’ Pour chaque facture: UNIQUEMENT Total TTC")
                prompt_parts.append("â†’ Date = date facture")

            elif nom == 'avis_ecriture':
                prompt_parts.append(f"\nPages {debut}-{fin}: AVIS D'Ã‰CRITURE")
                prompt_parts.append("â†’ Confirmations bancaires d'opÃ©rations")

        # Instructions finales
        prompt_parts.extend([
            "",
            "Pour CHAQUE opÃ©ration, extrais:",
            "- date_operation (format YYYY-MM-DD)",
            "- libelle (texte descriptif)",
            "- montant (dÃ©cimal positif)",
            "- type_operation (DEBIT ou CREDIT)",
            "",
            "IMPORTANT:",
            "- Regroupe les opÃ©rations multi-lignes",
            "- Ignore: en-tÃªtes, totaux, soldes d'ouverture/clÃ´ture",
            "- Objectif: ~88 opÃ©rations Ã©conomiques rÃ©elles (pas 150+)",
            "",
            "FORMAT JSON (uniquement, sans texte avant/aprÃ¨s):",
            "{",
            '  "operations": [',
            '    {"date_operation": "2024-01-15", "libelle": "...", "montant": 87.57, "type_operation": "DEBIT"}',
            "  ]",
            "}"
        ])

        return "\n".join(prompt_parts)

    def _extraire_par_chunks(self, sections_ordonnees: List[Dict], page_debut: int, page_fin: int) -> List[Dict]:
        """
        Extrait le PDF par chunks (fallback pour gros PDFs > 50 pages)

        Encapsule l'ancienne logique complexe de division en chunks.
        """
        # [ANCIENNE LOGIQUE ICI - Ã  implÃ©menter si nÃ©cessaire]
        # Pour l'instant, on suppose qu'on n'aura pas de PDFs > 50 pages
        print("   âš ï¸  Extraction par chunks non implÃ©mentÃ©e (fallback)")
        return []

    def _construire_prompt_extraction(self, section_type: str) -> str:
        """
        Construit un prompt d'extraction spÃ©cifique selon le type de section

        Args:
            section_type: Type de section ('releves_bancaires', 'factures_comptables', etc.)

        Returns:
            Prompt texte pour l'extraction
        """
        prompts = {
            'releves_bancaires': """Tu es un extracteur d'opÃ©rations bancaires de relevÃ©s de compte.

OBJECTIF: Extraire TOUTES les opÃ©rations bancaires de chaque page du relevÃ©.

Pour CHAQUE opÃ©ration, extrais:
- date_operation (format YYYY-MM-DD)
- libelle (texte complet sur une ligne)
- montant (nombre dÃ©cimal positif)
- type_operation (DEBIT ou CREDIT)

RÃˆGLES:
- Regroupe les opÃ©rations multi-lignes
- Ignore: en-tÃªtes, totaux, soldes d'ouverture/clÃ´ture
- Continue jusqu'Ã  la derniÃ¨re page

FORMAT JSON:
{
  "operations": [
    {"date_operation": "2024-01-15", "libelle": "PRLV SEPA...", "montant": 87.57, "type_operation": "DEBIT"}
  ]
}""",

            'factures_comptables': """Tu es un extracteur de factures comptables.

OBJECTIF: Pour CHAQUE facture, extraire UNIQUEMENT le montant Total TTC et la date de paiement.

IMPORTANT - SCI NON SOUMISE Ã€ TVA:
- Ignore les lignes de dÃ©tail (Provision, Honoraires, HT, TVA)
- Extrait UNIQUEMENT la ligne "Total TTC" ou "rÃ©gulÃ©e par prÃ©lÃ¨vement"
- UNE facture = UNE opÃ©ration (le Total TTC)

Pour chaque facture, extrais:
- date_operation: Date de paiement/prÃ©lÃ¨vement (YYYY-MM-DD)
- libelle: "Facture nÂ° XXXXXX" + fournisseur + "Total TTC"
- montant: Montant TTC (dÃ©cimal positif)
- type_operation: DEBIT

EXEMPLE:
Facture nÂ° 2024013227 du 02/01/2024, payÃ©e le 24/01/2024 par SEPA, Total TTC 213,60â‚¬
â†’ {"date_operation": "2024-01-24", "libelle": "Facture nÂ° 2024013227 - CRP 2C - Total TTC", "montant": 213.60, "type_operation": "DEBIT"}

FORMAT JSON:
{
  "operations": [
    {"date_operation": "2024-01-24", "libelle": "Facture nÂ° 2024013227...", "montant": 213.60, "type_operation": "DEBIT"}
  ]
}""",

            'factures_autres': """Tu es un extracteur de factures diverses (LEI, etc.).

OBJECTIF: Pour CHAQUE facture, extraire UNIQUEMENT le montant Total TTC.

Pour chaque facture, extrais:
- date_operation: Date de la facture (YYYY-MM-DD)
- libelle: "Facture" + objet + "Total TTC"
- montant: Montant TTC (dÃ©cimal positif)
- type_operation: DEBIT

FORMAT JSON:
{
  "operations": [
    {"date_operation": "2024-03-21", "libelle": "Facture LEI - Total TTC", "montant": 50.00, "type_operation": "DEBIT"}
  ]
}""",

            'bulletins_dividendes_scpi': """Tu es un extracteur de bulletins de dividendes SCPI.

OBJECTIF: Pour CHAQUE bulletin, extraire UNIQUEMENT le montant annoncÃ© de distribution.

IMPORTANT:
- UN bulletin = UNE opÃ©ration (mÃªme s'il fait plusieurs pages)
- Extrait le montant total annoncÃ© (pas les dÃ©tails ligne par ligne)
- Si un bulletin continue sur plusieurs pages, NE L'EXTRAIT QU'UNE FOIS

Pour chaque bulletin, extrais:
- date_operation: Date du bulletin (YYYY-MM-DD)
- libelle: "Bulletin SCPI" + nom SCPI + trimestre
- montant: Montant total annoncÃ© (dÃ©cimal positif)
- type_operation: CREDIT

EXEMPLE:
Bulletin ATLAND VOISIN - SCPI Epargne Pierre - 4Ã¨me trimestre 2023 - 7356,24â‚¬
â†’ {"date_operation": "2024-01-25", "libelle": "Bulletin SCPI Epargne Pierre - 4Ã¨me trimestre 2023", "montant": 7356.24, "type_operation": "CREDIT"}

FORMAT JSON:
{
  "operations": [
    {"date_operation": "2024-01-25", "libelle": "Bulletin SCPI...", "montant": 7356.24, "type_operation": "CREDIT"}
  ]
}""",

            'avis_ecriture': """Tu es un extracteur d'avis d'Ã©criture (confirmations bancaires).

OBJECTIF: Extraire les opÃ©rations confirmÃ©es.

Pour chaque avis, extrais:
- date_operation (YYYY-MM-DD)
- libelle (opÃ©ration confirmÃ©e)
- montant (dÃ©cimal positif)
- type_operation (DEBIT ou CREDIT)

FORMAT JSON:
{
  "operations": [
    {"date_operation": "2024-01-29", "libelle": "SCPI EPARGNE PIERRE...", "montant": 7356.24, "type_operation": "CREDIT"}
  ]
}""",

            'avis_operations_vm': """Tu es un extracteur d'avis d'opÃ©rations sur valeurs mobiliÃ¨res.

OBJECTIF: Extraire les dÃ©tails complets de CHAQUE opÃ©ration (achat/vente titres).

Pour chaque opÃ©ration, extrais:
- date_operation: Date de l'opÃ©ration (YYYY-MM-DD)
- libelle: "Achat" + quantitÃ© + nom titre + code ISIN + prix + montant total
- montant: Montant total opÃ©ration (dÃ©cimal positif)
- type_operation: DEBIT (achat) ou CREDIT (vente)

EXEMPLE:
Achat de 150 AMUNDI MSCI WORLD V (LU1781541179) Ã  15,631600 EUR = 2357,36 EUR
â†’ {"date_operation": "2024-01-30", "libelle": "Achat 150 AMUNDI MSCI WORLD V (LU1781541179) @ 15,631600 EUR", "montant": 2357.36, "type_operation": "DEBIT"}

FORMAT JSON:
{
  "operations": [
    {"date_operation": "2024-01-30", "libelle": "Achat 150 AMUNDI...", "montant": 2357.36, "type_operation": "DEBIT"}
  ]
}"""
        }

        # Retourner le prompt appropriÃ©, ou relevÃ©s bancaires par dÃ©faut
        return prompts.get(section_type, prompts['releves_bancaires'])

    def _determiner_section_chunk(self, chunk_page_debut: int, chunk_page_fin: int, sections_ordonnees: List[Dict]) -> str:
        """
        DÃ©termine le type de section principal d'un chunk basÃ© sur les pages qu'il contient

        Args:
            chunk_page_debut: PremiÃ¨re page du chunk (1-based)
            chunk_page_fin: DerniÃ¨re page du chunk (1-based)
            sections_ordonnees: Liste des sections triÃ©es par page de dÃ©but

        Returns:
            Type de section ('releves_bancaires', 'factures_comptables', etc.) ou 'unknown'
        """
        if not sections_ordonnees:
            return 'releves_bancaires'  # Fallback par dÃ©faut

        # Calculer quel pourcentage de chaque section est dans ce chunk
        section_overlaps = []
        for section in sections_ordonnees:
            # Calculer l'intersection
            overlap_debut = max(chunk_page_debut, section['page_debut'])
            overlap_fin = min(chunk_page_fin, section['page_fin'])

            if overlap_fin >= overlap_debut:
                overlap_pages = overlap_fin - overlap_debut + 1
                section_overlaps.append({
                    'nom': section['nom'],
                    'overlap': overlap_pages
                })

        # Retourner la section avec le plus de pages dans ce chunk
        if section_overlaps:
            section_dominante = max(section_overlaps, key=lambda x: x['overlap'])
            return section_dominante['nom']

        return 'releves_bancaires'  # Fallback

    def _diviser_pdf_en_chunks(self, max_pages_per_chunk: int = 5, page_debut: int = None, page_fin: int = None) -> List[str]:
        """
        Divise un PDF en plusieurs chunks de pages (fichiers temporaires)

        Args:
            max_pages_per_chunk: Nombre maximum de pages par chunk
            page_debut: PremiÃ¨re page Ã  inclure (1-based, optionnel)
            page_fin: DerniÃ¨re page Ã  inclure (1-based, optionnel)

        Returns:
            Liste des chemins des PDFs temporaires crÃ©Ã©s
        """
        try:
            import PyPDF2
            import tempfile

            # Ouvrir le PDF
            with open(self.pdf_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                total_pages = len(pdf_reader.pages)

                # DÃ©terminer la plage de pages Ã  traiter
                first_page = (page_debut - 1) if page_debut else 0  # Convert 1-based to 0-based
                last_page = page_fin if page_fin else total_pages
                pages_to_process = last_page - first_page

                if page_debut or page_fin:
                    print(f"ğŸ“„ PDF: extraction pages {page_debut or 1}-{page_fin or total_pages} (sur {total_pages} totales)")

                # Si petit PDF ou petite section, pas besoin de diviser
                if pages_to_process <= max_pages_per_chunk:
                    # CrÃ©er un PDF temporaire avec seulement les pages demandÃ©es
                    if page_debut or page_fin:
                        pdf_writer = PyPDF2.PdfWriter()
                        for page_num in range(first_page, last_page):
                            pdf_writer.add_page(pdf_reader.pages[page_num])

                        temp_file = tempfile.NamedTemporaryFile(
                            delete=False,
                            suffix=f'_pages_{page_debut or 1}-{page_fin or total_pages}.pdf'
                        )
                        with open(temp_file.name, 'wb') as out_f:
                            pdf_writer.write(out_f)
                        return [temp_file.name]
                    else:
                        return [self.pdf_path]

                print(f"ğŸ“„ PDF pages {page_debut or 1}-{page_fin or total_pages} â†’ Division en chunks de {max_pages_per_chunk} pages")

                # CrÃ©er les chunks pour la plage spÃ©cifiÃ©e
                chunk_paths = []
                for start_page in range(first_page, last_page, max_pages_per_chunk):
                    end_page = min(start_page + max_pages_per_chunk, last_page)

                    # CrÃ©er un nouveau PDF avec ce chunk
                    pdf_writer = PyPDF2.PdfWriter()
                    for page_num in range(start_page, end_page):
                        pdf_writer.add_page(pdf_reader.pages[page_num])

                    # Ã‰crire dans un fichier temporaire
                    temp_file = tempfile.NamedTemporaryFile(
                        delete=False,
                        suffix=f'_chunk_{start_page+1}-{end_page}.pdf'
                    )
                    with open(temp_file.name, 'wb') as out_f:
                        pdf_writer.write(out_f)

                    chunk_paths.append(temp_file.name)
                    print(f"   âœ“ Chunk crÃ©Ã©: pages {start_page+1}-{end_page} â†’ {os.path.basename(temp_file.name)}")

                return chunk_paths

        except ImportError:
            # PyPDF2 non disponible, retourner le PDF complet
            print("âš ï¸  PyPDF2 non disponible - traitement du PDF complet (risque de troncature)")
            return [self.pdf_path]
        except Exception as e:
            print(f"âš ï¸  Erreur division PDF: {e} - traitement du PDF complet")
            return [self.pdf_path]

    def extraire_evenements(self, date_debut: str = None, date_fin: str = None) -> List[Dict]:
        """
        Extrait tous les Ã©vÃ©nements du PDF via l'API PDF native de Claude

        STRATÃ‰GIE ANTI-TRONCATURE:
        - Si PDF > 5 pages: Division en chunks de 5 pages
        - Extraction sÃ©parÃ©e de chaque chunk
        - Fusion des rÃ©sultats + dÃ©duplication

        Args:
            date_debut: Date de dÃ©but de pÃ©riode (format YYYY-MM-DD, optionnel)
            date_fin: Date de fin de pÃ©riode (format YYYY-MM-DD, optionnel)

        Returns:
            Liste de dictionnaires d'Ã©vÃ©nements prÃªts pour GestionnaireEvenements
        """
        if not self.client:
            raise ValueError("ANTHROPIC_API_KEY non dÃ©finie - impossible d'extraire les PDF")

        if not os.path.exists(self.pdf_path):
            raise FileNotFoundError(f"PDF non trouvÃ©: {self.pdf_path}")

        print(f"ğŸ“„ Extraction du PDF: {os.path.basename(self.pdf_path)}")

        try:
            # Utiliser l'analyse en cache ou analyser si pas dÃ©jÃ  fait
            if self._analyse_cache:
                analyse = self._analyse_cache
            else:
                analyse = self.analyser_document()

            sections = analyse.get('sections', {})

            # DÃ©terminer les pages Ã  extraire (TOUTES les sections avec opÃ©rations)
            page_debut = None
            page_fin = None

            # NOUVELLE APPROCHE: Extraire TOUTES les sections dÃ©tectÃ©es
            # CrÃ©er une liste de sections ordonnÃ©es par page de dÃ©but
            sections_ordonnees = []
            for section_name, section_info in sections.items():
                if isinstance(section_info, dict):
                    debut = section_info.get('page_debut')
                    fin = section_info.get('page_fin')
                    if debut and fin:
                        sections_ordonnees.append({
                            'nom': section_name,
                            'page_debut': debut,
                            'page_fin': fin
                        })
                        print(f"ğŸ“‹ Section '{section_name}': pages {debut}-{fin}")

            # Trier par page de dÃ©but
            sections_ordonnees.sort(key=lambda x: x['page_debut'])

            if sections_ordonnees:
                page_debut = min(s['page_debut'] for s in sections_ordonnees)
                page_fin = max(s['page_fin'] for s in sections_ordonnees)
                print(f"âœ… Extraction globale: pages {page_debut}-{page_fin} (toutes sections)")
            else:
                print(f"âš ï¸  Aucune section dÃ©tectÃ©e - extraction complÃ¨te du PDF")
                sections_ordonnees = []

            #  APPROCHE SIMPLIFIÃ‰E: PDF complet en 1 seul appel si â‰¤ 50 pages
            import PyPDF2
            with open(self.pdf_path, 'rb') as f:
                pdf_reader = PyPDF2.PdfReader(f)
                total_pages = len(pdf_reader.pages)

            # StratÃ©gie d'extraction selon la taille
            if total_pages <= 50:
                print(f"ğŸ“„ PDF de {total_pages} pages â†’ Extraction en 1 seul appel API")
                operations = self._extraire_pdf_complet(sections_ordonnees)
            else:
                print(f"ğŸ“„ PDF de {total_pages} pages â†’ Extraction par chunks (fallback)")
                operations = self._extraire_par_chunks(sections_ordonnees, page_debut, page_fin)

            print(f"âœ… {len(operations)} opÃ©rations extraites du PDF")

            # RAPPROCHEMENT INTELLIGENT PAR CLAUDE API (Phase 2)
            if len(operations) > 0:
                rapprocheur = RapprocheurOperations()
                operations, metadata = rapprocheur.rapprocher(operations)
                # Stocker les justificatifs dans les mÃ©tadonnÃ©es pour audit
                self._justificatifs_metadata = metadata.get('justificatifs', {})
                print(f"âœ… {len(operations)} opÃ©rations aprÃ¨s rapprochement intelligent")

            # Enrichir et filtrer les opÃ©rations
            all_evenements = []
            nb_filtres_periode = 0
            nb_soldes_ouverture = 0

            for op in operations:
                # FILTRE 1: VÃ©rifier la pÃ©riode
                date_op = op['date_operation']
                if date_debut and date_op < date_debut:
                    nb_filtres_periode += 1
                    continue  # Ignorer les opÃ©rations avant la pÃ©riode
                if date_fin and date_op > date_fin:
                    nb_filtres_periode += 1
                    continue  # Ignorer les opÃ©rations aprÃ¨s la pÃ©riode

                # FILTRE 2: Exclure les soldes d'ouverture (non comptabilisables)
                libelle_norm = op['libelle'].upper().strip()
                est_solde_ouverture = any(pattern in libelle_norm for pattern in [
                    'ANCIEN SOLDE',
                    'SOLDE REPORTE',
                    'SOLDE REPORTÃ‰',
                    'SOLDE PRECEDENT',
                    'SOLDE PRÃ‰CÃ‰DENT',
                    'REPORT SOLDE'
                ])

                # SKIP les soldes d'ouverture - ne pas les crÃ©er en BD
                if est_solde_ouverture:
                    nb_soldes_ouverture += 1
                    continue

                evenement = {
                    'date_operation': op['date_operation'],
                    'libelle': op['libelle'],
                    'montant': float(op['montant']),
                    'type_operation': op['type_operation'],
                    'email_id': self.email_metadata.get('email_id'),
                    'email_from': self.email_metadata.get('email_from', 'pdf_manuel'),
                    'email_date': self.email_metadata.get('email_date', datetime.now()),
                    'email_subject': self.email_metadata.get('email_subject'),
                    'email_body': self.email_metadata.get('email_body', '')
                }
                all_evenements.append(evenement)

            print(f"âœ… TOTAL: {len(all_evenements)} Ã©vÃ©nements aprÃ¨s filtrage")
            if nb_filtres_periode > 0 or nb_soldes_ouverture > 0:
                filtres = []
                if nb_filtres_periode > 0:
                    filtres.append(f"{nb_filtres_periode} opÃ©rations hors pÃ©riode")
                if nb_soldes_ouverture > 0:
                    filtres.append(f"{nb_soldes_ouverture} soldes d'ouverture")
                print(f"   ({' + '.join(filtres)} exclus)")

            # Afficher info sur le filtrage de pÃ©riode
            if date_debut or date_fin:
                periode = f"{date_debut or '...'} â†’ {date_fin or '...'}"
                print(f"ğŸ“… PÃ©riode appliquÃ©e: {periode}")

            return all_evenements

        except json.JSONDecodeError as e:
            print(f"âŒ Erreur parsing JSON: {e}")
            print(f"   RÃ©ponse brute: {response_text[:500]}...")
            return []
        except Exception as e:
            print(f"âŒ Erreur extraction PDF: {e}")
            import traceback
            traceback.print_exc()
            return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FONCTIONS UTILITAIRES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def extraire_et_afficher(pdf_path: str, email_metadata: Optional[Dict] = None) -> List[Dict]:
    """
    Extrait et affiche les Ã©vÃ©nements d'un PDF

    Args:
        pdf_path: Chemin vers le PDF
        email_metadata: MÃ©tadonnÃ©es de l'email (optionnel)

    Returns:
        Liste des Ã©vÃ©nements extraits
    """
    extracteur = ExtracteurPDF(pdf_path, email_metadata)
    evenements = extracteur.extraire_evenements()

    print()
    print("=" * 80)
    print("Ã‰VÃ‰NEMENTS EXTRAITS")
    print("=" * 80)
    print()

    for i, evt in enumerate(evenements, 1):
        print(f"Ã‰vÃ©nement #{i}")
        print(f"  Date: {evt['date_operation']}")
        print(f"  LibellÃ©: {evt['libelle']}")
        print(f"  Montant: {evt['montant']}â‚¬")
        print(f"  Type: {evt['type_operation']}")
        print()

    print(f"ğŸ“Š Total: {len(evenements)} Ã©vÃ©nements")

    return evenements


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN (TESTS)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == '__main__':
    import sys

    print("=" * 80)
    print("EXTRACTEUR PDF - Test (API PDF Native)")
    print("=" * 80)
    print()

    if len(sys.argv) < 2:
        print("Usage: python extracteur_pdf.py <chemin_pdf>")
        print()
        print("Exemple:")
        print("  python extracteur_pdf.py 'Elements Comptables des 1-2-3T2024.pdf'")
        sys.exit(1)

    pdf_path = sys.argv[1]

    # Test avec mÃ©tadonnÃ©es fictives
    email_metadata = {
        'email_id': 'test_email_001',
        'email_from': 'comptabilite@test.com',
        'email_date': datetime.now(),
        'email_subject': 'Ã‰lÃ©ments comptables Q1-Q3 2024'
    }

    evenements = extraire_et_afficher(pdf_path, email_metadata)

    # Sauvegarder dans un fichier JSON pour inspection
    output_file = 'evenements_extraits.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(evenements, f, indent=2, ensure_ascii=False, default=str)

    print()
    print(f"ğŸ’¾ Ã‰vÃ©nements sauvegardÃ©s dans: {output_file}")
