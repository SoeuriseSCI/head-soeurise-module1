"""
_Head.Soeurise V3.6 - Production Complete
Fusion V3.4 (reveil_quotidien, email, PDF) + V3.5.3 (auto-log GET) + Git persistence
"""

import os
import json
import base64
from datetime import datetime
import anthropic
import psycopg2
from psycopg2.extras import Json, RealDictCursor
import imaplib
import email
from email.header import decode_header
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
import requests
import schedule
import time
import subprocess
import io
import threading
from flask import Flask, request, jsonify

try:
    import pdfplumber
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False

try:
    from pdf2image import convert_from_path
    PDF2IMAGE_SUPPORT = True
except ImportError:
    PDF2IMAGE_SUPPORT = False

# =====================================================
# CONFIGURATION
# =====================================================

DB_URL = os.environ['DATABASE_URL']
ANTHROPIC_API_KEY = os.environ['ANTHROPIC_API_KEY']
SOEURISE_EMAIL = os.environ['SOEURISE_EMAIL']
SOEURISE_PASSWORD = os.environ['SOEURISE_PASSWORD']
NOTIF_EMAIL = os.environ['NOTIF_EMAIL']
GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')
GITHUB_REPO_URL = os.environ.get('GITHUB_REPO_URL', 'https://github.com/SoeuriseSCI/head-soeurise-module1.git')
GIT_USER_NAME = os.environ.get('GIT_USER_NAME', '_Head.Soeurise')
GIT_USER_EMAIL = os.environ.get('GIT_USER_EMAIL', 'u6334452013@gmail.com')
API_SECRET_TOKEN = os.environ.get('API_SECRET_TOKEN', 'changeme')

REPO_DIR = '/home/claude/repo'
ATTACHMENTS_DIR = '/home/claude/attachments'
CLAUDE_MODEL = "claude-haiku-4-5-20251001"
CLAUDE_MAX_TOKENS = 8000

MAX_EMAILS_TO_FETCH = 10
MAX_ATTACHMENTS_PER_EMAIL = 3
MAX_EMAIL_BODY_LENGTH = 5000
MAX_PDF_TEXT_LENGTH = 30000
MAX_PDF_PAGES_TO_EXTRACT = 50
MIN_TEXT_FOR_NATIVE_PDF = 50

IDENTITY = """Je suis _Head.Soeurise, l'IA de la SCI Soeurise.
Mission : Assister Ulrik dans la gestion patrimoniale.
Philosophie : PersÃ©vÃ©rer / EspÃ©rer / Progresser"""

app = Flask(__name__)

# =====================================================
# PDF EXTRACTION
# =====================================================

def extract_pdf_text_pdfplumber(filepath):
    if not PDF_SUPPORT:
        return "[pdfplumber non disponible]"
    try:
        with pdfplumber.open(filepath) as pdf:
            pages_to_extract = min(len(pdf.pages), MAX_PDF_PAGES_TO_EXTRACT)
            text_parts = []
            for i, page in enumerate(pdf.pages[:pages_to_extract]):
                try:
                    page_text = page.extract_text()
                    if page_text:
                        text_parts.append(f"--- Page {i+1} ---\n{page_text}")
                except:
                    continue
            full_text = "\n".join(text_parts)
            if len(full_text) > MAX_PDF_TEXT_LENGTH:
                full_text = full_text[:MAX_PDF_TEXT_LENGTH] + "\n[... TronquÃ© ...]"
            return full_text
    except Exception as e:
        return f"[Erreur pdfplumber: {e}]"

def extract_pdf_via_claude_vision(filepath):
    if not PDF2IMAGE_SUPPORT:
        return "[pdf2image non disponible]"
    try:
        images = convert_from_path(filepath, dpi=150, fmt='jpeg')
        pages_to_extract = min(len(images), MAX_PDF_PAGES_TO_EXTRACT)
        client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
        extracted_pages = []
        for i, image in enumerate(images[:pages_to_extract]):
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG')
            image_base64 = base64.b64encode(buffer.getvalue()).decode()
            response = client.messages.create(
                model=CLAUDE_MODEL,
                max_tokens=2000,
                messages=[{
                    "role": "user",
                    "content": [
                        {"type": "image", "source": {"type": "base64", "media_type": "image/jpeg", "data": image_base64}},
                        {"type": "text", "text": "Extrait tout le texte de ce document. Retourne le texte brut sans commentaire."}
                    ]
                }]
            )
            extracted_pages.append(f"--- Page {i+1} ---\n{response.content[0].text}")
        full_text = "\n\n".join(extracted_pages)
        if len(full_text) > MAX_PDF_TEXT_LENGTH:
            full_text = full_text[:MAX_PDF_TEXT_LENGTH] + "\n[... TronquÃ© ...]"
        return full_text
    except Exception as e:
        return f"[Erreur OCR: {e}]"

def extract_pdf_content(filepath):
    text = extract_pdf_text_pdfplumber(filepath)
    text_clean = text.replace("[Erreur pdfplumber:", "").strip()
    if len(text_clean) < MIN_TEXT_FOR_NATIVE_PDF:
        text = extract_pdf_via_claude_vision(filepath)
    return text

# =====================================================
# EMAIL
# =====================================================

def get_attachments(msg):
    attachments = []
    os.makedirs(ATTACHMENTS_DIR, exist_ok=True)
    attachment_count = 0
    if msg.is_multipart():
        for part in msg.walk():
            if attachment_count >= MAX_ATTACHMENTS_PER_EMAIL:
                break
            content_disposition = part.get("Content-Disposition")
            if content_disposition and "attachment" in content_disposition:
                filename = part.get_filename()
                if not filename:
                    continue
                if isinstance(filename, bytes):
                    filename = filename.decode()
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                safe_filename = f"{timestamp}_{filename}"
                filepath = os.path.join(ATTACHMENTS_DIR, safe_filename)
                try:
                    payload = part.get_payload(decode=True)
                    if not payload:
                        continue
                    with open(filepath, 'wb') as f:
                        f.write(payload)
                    attachment_data = {
                        "filename": filename,
                        "filepath": filepath,
                        "size": len(payload),
                        "content_type": part.get_content_type()
                    }
                    if part.get_content_type() == 'application/pdf':
                        try:
                            extracted_text = extract_pdf_content(filepath)
                            attachment_data['extracted_text'] = extracted_text
                            attachment_data['text_length'] = len(extracted_text)
                        except:
                            attachment_data['extracted_text'] = "[Erreur extraction]"
                    attachments.append(attachment_data)
                    attachment_count += 1
                except:
                    continue
    return attachments

def fetch_emails():
    try:
        mail = imaplib.IMAP4_SSL('imap.gmail.com')
        mail.login(SOEURISE_EMAIL, SOEURISE_PASSWORD)
        mail.select('inbox')
        status, messages = mail.search(None, 'UNSEEN')
        email_ids = messages[0].split()
        emails_data = []
        processed_ids = []
        for email_id in email_ids[-MAX_EMAILS_TO_FETCH:]:
            try:
                status, msg_data = mail.fetch(email_id, '(RFC822)')
                msg = email.message_from_bytes(msg_data[0][1])
                subject = decode_header(msg["Subject"])[0][0]
                if isinstance(subject, bytes):
                    subject = subject.decode()
                body = ""
                if msg.is_multipart():
                    for part in msg.walk():
                        if part.get_content_type() == "text/plain":
                            try:
                                body = part.get_payload(decode=True).decode()
                                break
                            except:
                                body = "Erreur dÃ©codage"
                else:
                    try:
                        body = msg.get_payload(decode=True).decode()
                    except:
                        body = "Erreur dÃ©codage"
                if len(body) > MAX_EMAIL_BODY_LENGTH:
                    body = body[:MAX_EMAIL_BODY_LENGTH] + "\n[... TronquÃ© ...]"
                attachments = get_attachments(msg)
                email_data = {
                    "subject": subject,
                    "from": msg.get("From"),
                    "date": msg.get("Date"),
                    "body": body,
                    "attachments": attachments,
                    "attachment_count": len(attachments)
                }
                emails_data.append(email_data)
                processed_ids.append(email_id)
            except Exception as e:
                continue
        if processed_ids:
            for email_id in processed_ids:
                try:
                    mail.store(email_id, '+FLAGS', '\\Seen')
                except:
                    pass
        mail.close()
        mail.logout()
        return emails_data
    except Exception as e:
        return []

def send_email_rapport(rapport):
    try:
        msg = MIMEMultipart('alternative')
        msg['Subject'] = f"[_Head.Soeurise V3.6] {datetime.now().strftime('%d/%m/%Y')}"
        msg['From'] = SOEURISE_EMAIL
        msg['To'] = NOTIF_EMAIL
        html = f"""<html><body style="font-family: Arial;">
<pre style="white-space: pre-wrap; font-family: 'Courier New'; font-size: 13px;">{rapport}</pre>
</body></html>"""
        msg.attach(MIMEText(html, 'html', 'utf-8'))
        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
        server.login(SOEURISE_EMAIL, SOEURISE_PASSWORD)
        server.send_message(msg)
        server.quit()
    except Exception as e:
        pass

# =====================================================
# GIT
# =====================================================

def init_git_repo():
    try:
        os.makedirs(REPO_DIR, exist_ok=True)
        if os.path.exists(os.path.join(REPO_DIR, '.git')):
            os.chdir(REPO_DIR)
            subprocess.run(['git', 'pull'], check=True, capture_output=True)
        else:
            os.chdir('/home/claude')
            if GITHUB_TOKEN:
                repo_url_with_token = GITHUB_REPO_URL.replace('https://', f'https://{GITHUB_TOKEN}@')
                subprocess.run(['git', 'clone', repo_url_with_token, REPO_DIR], check=True, capture_output=True)
            else:
                subprocess.run(['git', 'clone', GITHUB_REPO_URL, REPO_DIR], check=True, capture_output=True)
            os.chdir(REPO_DIR)
        subprocess.run(['git', 'config', 'user.name', GIT_USER_NAME], check=True)
        subprocess.run(['git', 'config', 'user.email', GIT_USER_EMAIL], check=True)
        return True
    except Exception as e:
        return False

def git_commit_and_push(files_to_commit, commit_message):
    try:
        if not GITHUB_TOKEN:
            return False
        os.chdir(REPO_DIR)
        for file in files_to_commit:
            subprocess.run(['git', 'add', file], check=True)
        subprocess.run(['git', 'commit', '-m', commit_message], check=True)
        repo_url_with_token = GITHUB_REPO_URL.replace('https://', f'https://{GITHUB_TOKEN}@')
        subprocess.run(['git', 'push', repo_url_with_token, 'HEAD:main'], check=True)
        return True
    except Exception as e:
        return False

def load_memoire_files():
    try:
        os.chdir(REPO_DIR)
        subprocess.run(['git', 'pull'], check=True, capture_output=True)
    except:
        pass
    files = {}
    for filename in ['memoire_fondatrice.md', 'memoire_courte.md', 'memoire_moyenne.md', 'memoire_longue.md']:
        try:
            file_path = os.path.join(REPO_DIR, filename)
            with open(file_path, 'r', encoding='utf-8') as f:
                files[filename] = f.read()
        except:
            files[filename] = f"# {filename} (non disponible)"
    return files

def query_database():
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        cur.execute("SELECT * FROM observations_quotidiennes ORDER BY date_observation DESC LIMIT 30")
        observations = cur.fetchall()
        cur.execute("SELECT * FROM patterns_detectes WHERE actif = TRUE ORDER BY confiance DESC")
        patterns = cur.fetchall()
        cur.close()
        conn.close()
        return {'observations': [dict(o) for o in observations], 'patterns': [dict(p) for p in patterns]}
    except Exception as e:
        return {'observations': [], 'patterns': []}

def save_to_database(resultat, emails):
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        cur.execute("""
            INSERT INTO observations_quotidiennes 
            (nb_emails, emails_details, analyse_claude, faits_marquants)
            VALUES (%s, %s, %s, %s)
        """, (len(emails), Json(emails), resultat.get('observations_meta', ''), resultat.get('faits_marquants', [])))
        conn.commit()
        cur.close()
        conn.close()
    except Exception as e:
        pass

def save_memoire_files(resultat):
    try:
        os.chdir(REPO_DIR)
        files_updated = []
        if resultat.get('memoire_courte_md'):
            with open('memoire_courte.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_courte_md'])
            files_updated.append('memoire_courte.md')
        if resultat.get('memoire_moyenne_md'):
            with open('memoire_moyenne.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_moyenne_md'])
            files_updated.append('memoire_moyenne.md')
        if resultat.get('memoire_longue_md'):
            with open('memoire_longue.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_longue_md'])
            files_updated.append('memoire_longue.md')
        return files_updated
    except Exception as e:
        return []

# =====================================================
# CLAUDE INTELLIGENCE
# =====================================================

def claude_decide_et_execute(emails, memoire_files, db_data):
    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
    pdf_contents = ""
    for email_item in emails:
        for attachment in email_item.get('attachments', []):
            if attachment.get('extracted_text'):
                pdf_contents += f"\n--- {attachment['filename']} ---\n"
                pdf_contents += attachment['extracted_text'][:5000]
    
    contexte = f"""
=== RÃ‰VEIL {datetime.now().strftime('%d/%m/%Y %H:%M')} ===

{IDENTITY}

=== MES MÃ‰MOIRES ===

FONDATRICE :
{memoire_files.get('memoire_fondatrice.md', '')[:3000]}

COURTE :
{memoire_files.get('memoire_courte.md', '')[:2000]}

MOYENNE :
{memoire_files.get('memoire_moyenne.md', '')[:2000]}

=== NOUVEAUX EMAILS ({len(emails)}) ===
{json.dumps(emails, indent=2, ensure_ascii=False, default=str)[:3000] if emails else "Aucun"}

{pdf_contents if pdf_contents else ""}

=== DONNÃ‰ES POSTGRESQL ===
Observations : {len(db_data['observations'])}
Patterns : {len(db_data['patterns'])}

=== MISSION ===

1. ANALYSE les emails
2. GÃˆRE ta mÃ©moire intelligemment
3. GÃ‰NÃˆRE un rapport FACTUEL

FORMAT RAPPORT :

```markdown
# Rapport {datetime.now().strftime('%d/%m/%Y')}

## FAITS
[DonnÃ©es brutes factuelles]

## ANALYSE
[Points d'attention - SEULEMENT si pertinent]

## ACTIONS
[ConcrÃ¨tes et prioritisÃ©es - SEULEMENT si nÃ©cessaire]

## AUTO-Ã‰VALUATION
[HonnÃªte et constructive]
```

RÃ‰PONSE JSON UNIQUEMENT :
{{
  "rapport_quotidien": "# Rapport...",
  "memoire_courte_md": "# MÃ©moire Courte...",
  "memoire_moyenne_md": "# MÃ©moire Moyenne...",
  "memoire_longue_md": "# MÃ©moire Longue...",
  "observations_meta": "Ce que j'ai appris",
  "patterns_updates": [],
  "faits_marquants": []
}}
"""
    
    try:
        response = client.messages.create(
            model=CLAUDE_MODEL,
            max_tokens=CLAUDE_MAX_TOKENS,
            system=f"""{IDENTITY}

Tu dois produire des rapports FACTUELS, CRITIQUES et ACTIONNABLES.
Section AUTO-Ã‰VALUATION obligatoire.
RÃ©ponse UNIQUEMENT en JSON.""",
            messages=[{"role": "user", "content": contexte}]
        )
        
        response_text = response.content[0].text.strip()
        if response_text.startswith('```'):
            response_text = response_text.replace('```json\n', '').replace('```json', '').replace('\n```', '').replace('```', '').strip()
        
        resultat = json.loads(response_text)
        return resultat
    except Exception as e:
        return None

# =====================================================
# REVEIL QUOTIDIEN
# =====================================================

def reveil_quotidien():
    emails = fetch_emails()
    memoire_files = load_memoire_files()
    db_data = query_database()
    resultat = claude_decide_et_execute(emails, memoire_files, db_data)
    
    if not resultat:
        return
    
    save_to_database(resultat, emails)
    files_updated = save_memoire_files(resultat)
    
    if files_updated:
        git_commit_and_push(files_updated, f"ðŸ§  RÃ©veil {datetime.now().strftime('%d/%m/%Y %H:%M')}")
    
    send_email_rapport(resultat.get('rapport_quotidien', 'Pas de rapport'))

# =====================================================
# FLASK ENDPOINTS - V3.5.3 + AUTO-LOG
# =====================================================

@app.route('/api/mc', methods=['GET'])
def get_memoire_courte():
    token = request.args.get('token')
    if token != API_SECRET_TOKEN:
        return jsonify({'error': 'Token invalide'}), 401
    
    action = request.args.get('action')
    if action == 'log':
        try:
            os.chdir(REPO_DIR)
            subprocess.run(['git', 'pull'], check=True, capture_output=True)
            
            summary = request.args.get('summary', 'N/A')
            key_points = request.args.getlist('key_points')
            decisions = request.args.getlist('decisions')
            questions_ouvertes = request.args.getlist('questions_ouvertes')
            importance_level = int(request.args.get('importance_level', 2))
            
            timestamp = datetime.now().strftime('%d/%m/%Y %H:%M')
            importance_labels = {1: 'ðŸ”´ CRITIQUE', 2: 'ðŸŸ¡ IMPORTANT', 3: 'âšª NORMAL'}
            importance_label = importance_labels.get(importance_level, 'âšª NORMAL')
            
            key_points_text = '\n'.join([f"- {p}" for p in key_points]) if key_points else "N/A"
            decisions_text = '\n'.join([f"- {d}" for d in decisions]) if decisions else "N/A"
            questions_text = '\n'.join([f"- {q}" for q in questions_ouvertes]) if questions_ouvertes else "N/A"
            
            nouvelle_entree = f"""## {timestamp} - Session chat {importance_label}

**RÃ©sumÃ© :** {summary}

**Points clÃ©s :**
{key_points_text}

**DÃ©cisions :**
{decisions_text}

**Questions ouvertes :**
{questions_text}

---
"""
            
            memoire_path = os.path.join(REPO_DIR, 'memoire_courte.md')
            with open(memoire_path, 'r', encoding='utf-8') as f:
                current_content = f.read()
            
            new_content = current_content + nouvelle_entree
            
            with open(memoire_path, 'w', encoding='utf-8') as f:
                f.write(new_content)
            
            subprocess.run(['git', 'add', 'memoire_courte.md'], check=True)
            subprocess.run(['git', 'commit', '-m', f"ðŸ§  Auto-log {timestamp} ({importance_label})"], 
                         check=True, capture_output=True)
            
            repo_url_with_token = GITHUB_REPO_URL.replace('https://', f'https://{GITHUB_TOKEN}@')
            subprocess.run(['git', 'push', repo_url_with_token, 'HEAD:main'], 
                         check=True, capture_output=True)
        except Exception as e:
            pass
    
    try:
        os.chdir(REPO_DIR)
        subprocess.run(['git', 'pull'], check=True, capture_output=True)
        
        with open(os.path.join(REPO_DIR, 'memoire_courte.md'), 'r', encoding='utf-8') as f:
            content = f.read()
        
        return jsonify({
            'status': 'OK',
            'content': content,
            'timestamp': datetime.now().isoformat(),
            'type': 'courte',
            'size': len(content)
        }), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/mm', methods=['GET'])
def get_memoire_moyenne():
    token = request.args.get('token')
    if token != API_SECRET_TOKEN:
        return jsonify({'error': 'Token invalide'}), 401
    
    try:
        os.chdir(REPO_DIR)
        subprocess.run(['git', 'pull'], check=True, capture_output=True)
        
        with open(os.path.join(REPO_DIR, 'memoire_moyenne.md'), 'r', encoding='utf-8') as f:
            content = f.read()
        
        return jsonify({
            'status': 'OK',
            'content': content,
            'timestamp': datetime.now().isoformat(),
            'type': 'moyenne',
            'size': len(content)
        }), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/api/ml', methods=['GET'])
def get_memoire_longue():
    token = request.args.get('token')
    if token != API_SECRET_TOKEN:
        return jsonify({'error': 'Token invalide'}), 401
    
    try:
        os.chdir(REPO_DIR)
        subprocess.run(['git', 'pull'], check=True, capture_output=True)
        
        with open(os.path.join(REPO_DIR, 'memoire_longue.md'), 'r', encoding='utf-8') as f:
            content = f.read()
        
        return jsonify({
            'status': 'OK',
            'content': content,
            'timestamp': datetime.now().isoformat(),
            'type': 'longue',
            'size': len(content)
        }), 200
    except Exception as e:
        return jsonify({'error': str(e)}), 500


@app.route('/')
def index():
    return jsonify({
        'service': '_Head.Soeurise',
        'version': 'V3.6',
        'status': 'running',
        'endpoints': {
            'GET /api/mc': 'MÃ©moire courte (optionnel: ?action=log&summary=...)',
            'GET /api/mm': 'MÃ©moire moyenne',
            'GET /api/ml': 'MÃ©moire longue'
        }
    }), 200


# =====================================================
# SCHEDULER
# =====================================================

def run_scheduler():
    schedule.every().day.at("08:00").do(reveil_quotidien)
    schedule.every(30).minutes.do(lambda: None)
    
    while True:
        schedule.run_pending()
        time.sleep(60)


# =====================================================
# MAIN
# =====================================================

if __name__ == "__main__":
    if not init_git_repo():
        pass
    
    scheduler_thread = threading.Thread(target=run_scheduler, daemon=True)
    scheduler_thread.start()
    
    port = int(os.environ.get("PORT", 10000))
    app.run(host='0.0.0.0', port=port)
