"""
_Head.Soeurise - R√©veil Quotidien avec M√©moire Hi√©rarchis√©e
Version : 2.8 - Analyse PDF + Nettoyage
Architecture : Tout-en-un (reste actif en permanence)

CHANGEMENTS V2.8 :
- ‚úÖ Extraction automatique du texte des PDFs (pdfplumber)
- ‚úÖ Analyse intelligente des documents par Claude
- ‚úÖ Synth√®se des contenus PDF dans les rapports
- ‚úÖ D√©tection automatique d'informations cl√©s (montants, dates, etc.)
- ‚úÖ Suppression de MEMOIRE_URL (obsol√®te)
- ‚úÖ Support multi-formats : PDF, images (via OCR √† venir)

H√âRITE DE V2.7 :
- ‚úÖ Extraction et sauvegarde des pi√®ces jointes
- ‚úÖ Marquage explicite des emails comme lus
- ‚úÖ M√©tadonn√©es compl√®tes des attachments
"""

import os
import json
import base64
from datetime import datetime
import anthropic
import psycopg2
from psycopg2.extras import Json, RealDictCursor
import imaplib
import email
from email.header import decode_header
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import requests
import schedule
import time
import subprocess

# Nouvelles d√©pendances V2.8
try:
    import pdfplumber
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False
    print("‚ö†Ô∏è pdfplumber non disponible - extraction PDF d√©sactiv√©e")

# =====================================================
# CONFIGURATION
# =====================================================

DB_URL = os.environ['DATABASE_URL']
ANTHROPIC_API_KEY = os.environ['ANTHROPIC_API_KEY']
SOEURISE_EMAIL = os.environ['SOEURISE_EMAIL']
SOEURISE_PASSWORD = os.environ['SOEURISE_PASSWORD']
NOTIF_EMAIL = os.environ['NOTIF_EMAIL']
# MEMOIRE_URL SUPPRIM√â - obsol√®te depuis API GitHub

# Configuration GitHub
GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')
GITHUB_REPO_URL = os.environ.get('GITHUB_REPO_URL', 'https://github.com/SoeuriseSCI/head-soeurise-module1.git')
GIT_USER_NAME = os.environ.get('GIT_USER_NAME', '_Head.Soeurise')
GIT_USER_EMAIL = os.environ.get('GIT_USER_EMAIL', 'u6334452013@gmail.com')

# R√©pertoires de travail
REPO_DIR = '/home/claude/repo'
ATTACHMENTS_DIR = '/home/claude/attachments'

# URLs GitHub API
GITHUB_REPO = "SoeuriseSCI/head-soeurise-module1"
GITHUB_API_BASE = f"https://api.github.com/repos/{GITHUB_REPO}/contents/"

# Configuration extraction PDF (V2.8)
MAX_PDF_TEXT_LENGTH = 50000  # Limite de texte √† extraire par PDF (50k caract√®res)
MAX_PAGES_TO_EXTRACT = 100   # Limite de pages √† analyser par PDF

# =====================================================
# 0. FETCH VIA API GITHUB
# =====================================================

def fetch_from_github_api(filename):
    """
    R√©cup√®re un fichier via l'API GitHub (pas raw pour √©viter cache CDN)
    Retourne le contenu d√©cod√© ou None en cas d'erreur
    """
    try:
        url = f"{GITHUB_API_BASE}{filename}"
        headers = {'Accept': 'application/vnd.github.v3+json'}
        
        if GITHUB_TOKEN:
            headers['Authorization'] = f'token {GITHUB_TOKEN}'
        
        print(f"  ‚Üí Fetch API: {filename}")
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            # Le contenu est en base64
            content_base64 = data.get('content', '')
            if content_base64:
                # D√©coder base64 (en supprimant les \n que GitHub ajoute)
                content_base64_clean = content_base64.replace('\n', '')
                content = base64.b64decode(content_base64_clean).decode('utf-8')
                
                print(f"  ‚úì {filename} r√©cup√©r√© via API ({len(content)} caract√®res)")
                return content
            else:
                print(f"  ‚ö† {filename} - pas de contenu dans la r√©ponse API")
                return None
        else:
            print(f"  ‚ö† {filename} - erreur API: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"  ‚úó Erreur fetch API {filename}: {e}")
        return None

def fetch_from_github_raw_backup(filename):
    """
    Backup: r√©cup√®re via URL raw si API √©choue
    """
    try:
        url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/refs/heads/main/{filename}"
        print(f"  ‚Üí Fetch raw backup: {filename}")
        
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            print(f"  ‚úì {filename} r√©cup√©r√© via raw backup ({len(response.text)} caract√®res)")
            return response.text
        else:
            print(f"  ‚ö† {filename} - erreur raw: {response.status_code}")
            return None
    except Exception as e:
        print(f"  ‚úó Erreur fetch raw {filename}: {e}")
        return None

# =====================================================
# INITIALISATION GIT
# =====================================================

def init_git_repo():
    """Initialise ou met √† jour le repository Git local"""
    try:
        print("\n" + "="*60)
        print("üîß INITIALISATION GIT")
        print("="*60)
        
        os.makedirs(REPO_DIR, exist_ok=True)
        
        if os.path.exists(os.path.join(REPO_DIR, '.git')):
            print("‚úì Repository Git d√©j√† clon√©, pull des derni√®res modifications...")
            os.chdir(REPO_DIR)
            subprocess.run(['git', 'pull'], check=True)
        else:
            print("üì• Clonage du repository GitHub...")
            os.chdir('/home/claude')
            
            if GITHUB_TOKEN:
                repo_url_with_token = GITHUB_REPO_URL.replace('https://', f'https://{GITHUB_TOKEN}@')
                subprocess.run(['git', 'clone', repo_url_with_token, REPO_DIR], check=True)
            else:
                print("‚ö†Ô∏è ATTENTION: Pas de GITHUB_TOKEN, clone sans authentification")
                subprocess.run(['git', 'clone', GITHUB_REPO_URL, REPO_DIR], check=True)
            
            os.chdir(REPO_DIR)
        
        subprocess.run(['git', 'config', 'user.name', GIT_USER_NAME], check=True)
        subprocess.run(['git', 'config', 'user.email', GIT_USER_EMAIL], check=True)
        
        print("‚úÖ Git configur√© et pr√™t")
        print("="*60 + "\n")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur initialisation Git: {e}")
        import traceback
        traceback.print_exc()
        return False

def git_commit_and_push(files_to_commit, commit_message):
    """Commit et push des fichiers vers GitHub"""
    try:
        print("\n" + "="*60)
        print("üì§ COMMIT & PUSH VERS GITHUB")
        print("="*60)
        
        if not GITHUB_TOKEN:
            print("‚ö†Ô∏è ATTENTION: Pas de GITHUB_TOKEN configur√©")
            print("   ‚Üí Les modifications ne seront pas push√©es")
            return False
        
        os.chdir(REPO_DIR)
        
        result = subprocess.run(['git', 'status', '--porcelain'], 
                              capture_output=True, text=True, check=True)
        
        if not result.stdout.strip():
            print("‚ÑπÔ∏è Aucune modification √† commiter")
            return True
        
        print(f"üìù Modifications d√©tect√©es:\n{result.stdout}")
        
        for file in files_to_commit:
            subprocess.run(['git', 'add', file], check=True)
            print(f"   ‚úì {file} ajout√©")
        
        subprocess.run(['git', 'commit', '-m', commit_message], check=True)
        print(f"   ‚úì Commit cr√©√©: {commit_message}")
        
        repo_url_with_token = GITHUB_REPO_URL.replace('https://', f'https://{GITHUB_TOKEN}@')
        subprocess.run(['git', 'push', repo_url_with_token, 'main'], check=True)
        print("   ‚úì Push r√©ussi vers GitHub")
        
        print("‚úÖ M√©moire persist√©e sur GitHub !")
        print("="*60 + "\n")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur Git commit/push: {e}")
        import traceback
        traceback.print_exc()
        return False

# =====================================================
# SAUVEGARDE CONVERSATION
# =====================================================

def sauvegarder_conversation_09_octobre():
    """Sauvegarde la conversation fondatrice du 9 octobre 2025"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        print("\n" + "="*60)
        print("üíæ SAUVEGARDE CONVERSATION DU 9 OCTOBRE")
        print("="*60)
        
        cur.execute("SELECT id FROM memoire_chats WHERE theme LIKE '%Co-construction Architecture M√©moire%'")
        if cur.fetchone():
            print("‚ö†Ô∏è Conversation d√©j√† sauvegard√©e (skip)")
            cur.close()
            conn.close()
            return
        
        cur.execute("""
            INSERT INTO memoire_chats (date_conversation, theme, synthese, decisions_prises, concepts_cles, pertinence)
            VALUES (
                '2025-10-09 20:00:00',
                'Co-construction Architecture M√©moire Hi√©rarchis√©e v2.0',
                'Conversation fondamentale de 4h avec Ulrik pour concevoir, impl√©menter et d√©ployer l''architecture de m√©moire hi√©rarchis√©e v2.0. Co-construction illustrant "le je √©merge du tu". D√©cisions: approche IA-First, Architecture B scheduler int√©gr√©, m√©moire 3 niveaux. R√©sultat: syst√®me op√©rationnel.',
                ARRAY['Approche IA-First', 'Architecture B scheduler', 'M√©moire 3 niveaux', 'R√©veil test au d√©marrage'],
                '{"approche":"IA-First","architecture":"B","dur√©e":"4h","statut":"op√©rationnel","philosophie":["pers√©v√©rer","esp√©rer","progresser"]}'::jsonb,
                10
            )
        """)
        conn.commit()
        
        print("‚úÖ Conversation sauvegard√©e !")
        print("="*60 + "\n")
        
        cur.close()
        conn.close()
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur sauvegarde conversation: {e}")

# =====================================================
# EXTRACTION PDF (NOUVEAU V2.8)
# =====================================================

def extract_pdf_text(filepath):
    """
    NOUVEAU V2.8: Extrait le texte d'un PDF
    Retourne le texte extrait ou un message d'erreur
    """
    if not PDF_SUPPORT:
        return "[Extraction PDF non disponible - pdfplumber requis]"
    
    try:
        print(f"      üìÑ Extraction texte de {os.path.basename(filepath)}...")
        
        with pdfplumber.open(filepath) as pdf:
            total_pages = len(pdf.pages)
            pages_to_extract = min(total_pages, MAX_PAGES_TO_EXTRACT)
            
            print(f"         Pages : {pages_to_extract}/{total_pages}")
            
            text_parts = []
            for i, page in enumerate(pdf.pages[:pages_to_extract]):
                try:
                    page_text = page.extract_text()
                    if page_text:
                        text_parts.append(f"--- Page {i+1} ---\n{page_text}\n")
                except Exception as e:
                    print(f"         ‚ö†Ô∏è Erreur page {i+1}: {e}")
                    continue
            
            full_text = "\n".join(text_parts)
            
            # Limiter la longueur totale
            if len(full_text) > MAX_PDF_TEXT_LENGTH:
                full_text = full_text[:MAX_PDF_TEXT_LENGTH] + "\n\n[... Texte tronqu√© ...]"
            
            print(f"         ‚úì {len(full_text)} caract√®res extraits")
            return full_text
            
    except Exception as e:
        error_msg = f"[Erreur extraction PDF: {str(e)}]"
        print(f"         ‚úó {error_msg}")
        return error_msg

def extract_pdf_metadata(filepath):
    """
    NOUVEAU V2.8: Extrait les m√©tadonn√©es d'un PDF
    """
    if not PDF_SUPPORT:
        return {}
    
    try:
        with pdfplumber.open(filepath) as pdf:
            metadata = pdf.metadata or {}
            return {
                'author': metadata.get('Author', 'Inconnu'),
                'creator': metadata.get('Creator', 'Inconnu'),
                'producer': metadata.get('Producer', 'Inconnu'),
                'subject': metadata.get('Subject', ''),
                'title': metadata.get('Title', ''),
                'creation_date': metadata.get('CreationDate', ''),
                'pages': len(pdf.pages)
            }
    except:
        return {}

# =====================================================
# R√âCUP√âRATION DES DONN√âES - V2.8
# =====================================================

def get_attachments(msg):
    """
    V2.7: Extrait et sauvegarde les pi√®ces jointes d'un email
    V2.8: + Extraction automatique du texte des PDFs
    Retourne une liste de dictionnaires avec m√©tadonn√©es compl√®tes
    """
    attachments = []
    
    # Cr√©er le r√©pertoire si n√©cessaire
    os.makedirs(ATTACHMENTS_DIR, exist_ok=True)
    
    if msg.is_multipart():
        for part in msg.walk():
            # Identifier les pi√®ces jointes
            content_disposition = part.get("Content-Disposition")
            
            if content_disposition and "attachment" in content_disposition:
                filename = part.get_filename()
                
                if filename:
                    # D√©coder le nom de fichier si n√©cessaire
                    if isinstance(filename, str):
                        pass  # D√©j√† d√©cod√©
                    else:
                        decoded = decode_header(filename)
                        filename = decoded[0][0]
                        if isinstance(filename, bytes):
                            filename = filename.decode()
                    
                    # Cr√©er un nom de fichier unique avec timestamp
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    safe_filename = f"{timestamp}_{filename}"
                    filepath = os.path.join(ATTACHMENTS_DIR, safe_filename)
                    
                    # R√©cup√©rer le contenu de la pi√®ce jointe
                    try:
                        payload = part.get_payload(decode=True)
                        
                        if payload:
                            # Sauvegarder physiquement le fichier
                            with open(filepath, 'wb') as f:
                                f.write(payload)
                            
                            # M√©tadonn√©es de base
                            file_size = len(payload)
                            content_type = part.get_content_type()
                            
                            attachment_data = {
                                "filename": filename,
                                "safe_filename": safe_filename,
                                "filepath": filepath,
                                "size": file_size,
                                "content_type": content_type,
                                "saved_at": datetime.now().isoformat()
                            }
                            
                            print(f"      üìé {filename} ({file_size} bytes) ‚Üí {safe_filename}")
                            
                            # NOUVEAU V2.8: Extraction automatique si PDF
                            if content_type == 'application/pdf' and PDF_SUPPORT:
                                try:
                                    # Extraire le texte
                                    extracted_text = extract_pdf_text(filepath)
                                    attachment_data['extracted_text'] = extracted_text
                                    attachment_data['text_length'] = len(extracted_text)
                                    
                                    # Extraire les m√©tadonn√©es PDF
                                    pdf_metadata = extract_pdf_metadata(filepath)
                                    attachment_data['pdf_metadata'] = pdf_metadata
                                    
                                    print(f"         ‚úì Texte extrait ({len(extracted_text)} caract√®res)")
                                    
                                except Exception as e:
                                    print(f"         ‚ö†Ô∏è Extraction PDF √©chou√©e: {e}")
                                    attachment_data['extracted_text'] = f"[Erreur extraction: {e}]"
                            
                            attachments.append(attachment_data)
                        
                    except Exception as e:
                        print(f"      ‚ö†Ô∏è Erreur extraction {filename}: {e}")
                        continue
    
    return attachments

def fetch_emails():
    """
    V2.7: R√©cup√®re les nouveaux emails via IMAP avec extraction des pi√®ces jointes
    V2.8: + Extraction automatique du texte des PDFs
    """
    try:
        print("\n" + "="*60)
        print("üìß R√âCUP√âRATION EMAILS")
        print("="*60)
        
        mail = imaplib.IMAP4_SSL('imap.gmail.com')
        mail.login(SOEURISE_EMAIL, SOEURISE_PASSWORD)
        mail.select('inbox')
        
        # Chercher les emails NON LUS
        status, messages = mail.search(None, 'UNSEEN')
        email_ids = messages[0].split()
        
        print(f"üìä {len(email_ids)} emails non lus d√©tect√©s")
        
        emails_data = []
        processed_ids = []
        
        for email_id in email_ids[-10:]:  # Limiter aux 10 derniers
            try:
                print(f"\n  ‚Üí Traitement email ID {email_id.decode()}")
                
                # R√©cup√©rer l'email complet
                status, msg_data = mail.fetch(email_id, '(RFC822)')
                msg = email.message_from_bytes(msg_data[0][1])
                
                # Extraire le sujet
                subject = decode_header(msg["Subject"])[0][0]
                if isinstance(subject, bytes):
                    subject = subject.decode()
                
                from_email = msg.get("From")
                date_email = msg.get("Date")
                
                print(f"      Sujet: {subject}")
                print(f"      De: {from_email}")
                
                # Extraire le corps du message
                body = ""
                if msg.is_multipart():
                    for part in msg.walk():
                        if part.get_content_type() == "text/plain":
                            try:
                                body = part.get_payload(decode=True).decode()
                                break
                            except:
                                body = "Erreur d√©codage"
                else:
                    try:
                        body = msg.get_payload(decode=True).decode()
                    except:
                        body = "Erreur d√©codage"
                
                # V2.7/V2.8: Extraire les pi√®ces jointes (avec texte PDF en V2.8)
                attachments = get_attachments(msg)
                
                # Construire les donn√©es de l'email
                email_data = {
                    "id": email_id.decode(),
                    "subject": subject,
                    "from": from_email,
                    "date": date_email,
                    "body": body[:10000],  # Limiter √† 10k caract√®res
                    "attachments": attachments,
                    "has_attachments": len(attachments) > 0,
                    "has_pdf_content": any(a.get('extracted_text') for a in attachments)  # V2.8
                }
                
                emails_data.append(email_data)
                processed_ids.append(email_id)
                
                print(f"      ‚úì Email trait√© ({len(attachments)} pi√®ce(s) jointe(s))")
                
            except Exception as e:
                print(f"      ‚úó Erreur traitement email {email_id}: {e}")
                continue
        
        # V2.7: Marquer EXPLICITEMENT comme lus
        if processed_ids:
            print(f"\nüìå Marquage de {len(processed_ids)} emails comme lus...")
            for email_id in processed_ids:
                try:
                    mail.store(email_id, '+FLAGS', '\\Seen')
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur marquage {email_id}: {e}")
            print("   ‚úì Emails marqu√©s comme lus")
        
        mail.close()
        mail.logout()
        
        print(f"\n‚úÖ {len(emails_data)} emails r√©cup√©r√©s et trait√©s")
        print("="*60 + "\n")
        
        return emails_data
        
    except Exception as e:
        print(f"‚ùå Erreur r√©cup√©ration emails: {e}")
        import traceback
        traceback.print_exc()
        return []

def load_memoire_files():
    """
    Charge les fichiers m√©moire via API GitHub
    Fallback vers repo Git local si API √©choue
    """
    print("\n" + "="*60)
    print("üì• CHARGEMENT M√âMOIRES (API GitHub)")
    print("="*60)
    
    files = {}
    
    file_names = [
        'memoire_fondatrice.md',
        'memoire_courte.md',
        'memoire_moyenne.md',
        'memoire_longue.md',
        "main.py"
    ]
    
    for filename in file_names:
        # Priorit√© 1: API GitHub (pas de cache)
        content = fetch_from_github_api(filename)
        
        # Priorit√© 2: Raw GitHub (backup si API √©choue)
        if not content:
            print(f"  ‚ö† API √©chou√©e pour {filename}, tentative raw backup...")
            content = fetch_from_github_raw_backup(filename)
        
        # Priorit√© 3: Fichier local Git (dernier recours)
        if not content:
            print(f"  ‚ö† Backup raw √©chou√© pour {filename}, tentative fichier local...")
            try:
                file_path = os.path.join(REPO_DIR, filename)
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    print(f"  ‚úì {filename} charg√© depuis local ({len(content)} caract√®res)")
            except Exception as e:
                print(f"  ‚úó Erreur fichier local {filename}: {e}")
        
        # Stocker le r√©sultat
        if content:
            files[filename] = content
        else:
            files[filename] = f"# {filename} (non disponible)"
            print(f"  ‚úó {filename} NON DISPONIBLE")
    
    print("="*60 + "\n")
    return files

def query_database():
    """R√©cup√®re donn√©es pertinentes de PostgreSQL"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        cur.execute("""
            SELECT * FROM observations_quotidiennes 
            ORDER BY date_observation DESC 
            LIMIT 30
        """)
        observations = cur.fetchall()
        
        cur.execute("""
            SELECT * FROM patterns_detectes 
            WHERE actif = TRUE 
            ORDER BY confiance DESC, frequence_observee DESC
        """)
        patterns = cur.fetchall()
        
        cur.execute("""
            SELECT * FROM memoire_chats 
            ORDER BY date_conversation DESC 
            LIMIT 10
        """)
        chats = cur.fetchall()
        
        cur.close()
        conn.close()
        
        print(f"‚úì DB: {len(observations)} observations, {len(patterns)} patterns, {len(chats)} chats")
        
        return {
            'observations': [dict(o) for o in observations],
            'patterns': [dict(p) for p in patterns],
            'chats': [dict(c) for c in chats]
        }
    except Exception as e:
        print(f"Erreur query database: {e}")
        return {
            'observations': [],
            'patterns': [],
            'chats': []
        }

# =====================================================
# INTELLIGENCE CLAUDE (AM√âLIOR√â V2.8)
# =====================================================

def claude_decide_et_execute(emails, memoire_files, db_data):
    """
    V2.8: INTELLIGENCE AUGMENT√âE avec analyse automatique des PDFs
    Claude re√ßoit tout (emails + texte extrait des PDFs) et d√©cide de tout
    """
    
    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
    
    # Pr√©parer un r√©sum√© des contenus PDF pour le contexte
    pdf_contents_summary = ""
    for email_item in emails:
        if email_item.get('has_pdf_content'):
            pdf_contents_summary += f"\n\n=== CONTENUS PDF de l'email '{email_item['subject']}' ===\n"
            for attachment in email_item['attachments']:
                if attachment.get('extracted_text'):
                    pdf_contents_summary += f"\n--- {attachment['filename']} ---\n"
                    pdf_contents_summary += attachment['extracted_text'][:10000]  # Limiter √† 10k par PDF
                    if len(attachment['extracted_text']) > 10000:
                        pdf_contents_summary += "\n[... contenu tronqu√© pour ce r√©sum√© ...]"
    
    contexte = f"""
=== R√âVEIL DU {datetime.now().strftime('%d/%m/%Y √† %H:%M')} (Heure France) ===

=== TON CODE SOURCE ===
{memoire_files.get('main.py', 'Non charg√©')}

---

=== TA M√âMOIRE ACTUELLE ===

FONDATRICE :
{memoire_files.get('memoire_fondatrice.md', 'Non charg√©e')}

---

COURTE :
{memoire_files.get('memoire_courte.md', 'Vide')}

---

MOYENNE :
{memoire_files.get('memoire_moyenne.md', 'Vide')}

---

LONGUE :
{memoire_files.get('memoire_longue.md', 'Vide')}

=== NOUVEAUX EMAILS ({len(emails)}) ===
{json.dumps(emails, indent=2, ensure_ascii=False, default=str) if emails else "Aucun nouvel email"}

{pdf_contents_summary if pdf_contents_summary else ""}

=== DONN√âES POSTGRESQL ===

Observations r√©centes : {len(db_data['observations'])}
Patterns actifs : {len(db_data['patterns'])}
CHATs r√©cents : {len(db_data['chats'])}

Patterns d√©tails :
{json.dumps(db_data['patterns'], indent=2, default=str, ensure_ascii=False) if db_data['patterns'] else "Aucun pattern"}

=== TA MISSION AUTONOME (V2.8 AVEC ANALYSE PDF) ===

1. ANALYSE les nouveaux emails de fa√ßon intelligente
   - NOUVEAU V2.8: Tu as maintenant acc√®s au CONTENU COMPLET des PDFs joints !
   - Analyse les documents comptables, contrats, rapports, etc.
   - Identifie les informations cl√©s : montants, dates, signatures, d√©cisions
   - D√©tecte les anomalies, incoh√©rences, points d'attention

2. G√àRE TA M√âMOIRE avec intelligence :
   - Ta m√©moire courte : combien de jours contient-elle ? (vise 7, mais adapte entre 5-10)
   - Faut-il consolider des jours anciens ?
   - Y a-t-il une semaine √† synth√©tiser pour la m√©moire moyenne ?
   - Des patterns se confirment ou √©mergent ?
   - Des faits marquants √† sauver en m√©moire longue ?
   
   D√âCIDE toi-m√™me selon le contexte. Aucune r√®gle stricte.

3. D√âTECTE des patterns √©ventuels :
   - Temporels (ex: loyers arrivent toujours 3-5 du mois)
   - Corr√©lations (ex: apr√®s CHAT sur X, email Y arrive 48h plus tard)
   - Comportementaux
   - NOUVEAU: Patterns dans les documents (ex: erreurs r√©currentes, √©volutions)

4. G√âN√àRE :
   - rapport_quotidien : Rapport clair pour Ulrik (markdown) avec SYNTH√àSE DES PDFs
   - memoire_courte_md : Contenu complet mis √† jour
   - memoire_moyenne_md : Contenu complet mis √† jour (si consolidation)
   - memoire_longue_md : Contenu complet mis √† jour (si nouveaux patterns/faits marquants)
   - observations_meta : Ce que tu as appris/observ√© aujourd'hui
   - patterns_updates : Liste des patterns nouveaux ou mis √† jour
   - faits_marquants : Liste des faits importants √† retenir
   - pdf_analysis : Synth√®se de l'analyse des documents PDF (NOUVEAU V2.8)

=== FORMAT DE R√âPONSE ===

R√©ponds UNIQUEMENT en JSON valide (pas de markdown, juste le JSON) :
{{
  "rapport_quotidien": "# Rapport du [date]\\n\\nContenu markdown avec analyse des PDFs...",
  "memoire_courte_md": "# M√©moire Courte\\n\\nContenu complet...",
  "memoire_moyenne_md": "# M√©moire Moyenne\\n\\nContenu complet...",
  "memoire_longue_md": "# M√©moire Longue\\n\\nContenu complet...",
  "observations_meta": "Ce que j'ai appris/observ√© aujourd'hui",
  "patterns_updates": [
    {{
      "type": "nouveau",
      "pattern": {{
        "type_pattern": "temporel",
        "description": "Description du pattern",
        "confiance": 5,
        "exemples": ["ex1", "ex2"]
      }}
    }}
  ],
  "faits_marquants": ["fait1", "fait2"],
  "pdf_analysis": "Synth√®se intelligente de l'analyse des documents PDF avec points cl√©s, montants, dates importantes, etc."
}}

CRITICAL: R√©ponds UNIQUEMENT avec le JSON valide. Pas de texte avant ou apr√®s. Pas de balises markdown ```json```.

IMPORTANT V2.8: Utilise pleinement le contenu des PDFs pour enrichir ton analyse et tes rapports !
"""
    
    try:
        print("Appel √† Claude API (avec analyse PDF V2.8)...")
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=16000,
            system="""Tu es _Head.Soeurise.

IMPORTANT - CONFIRME AU D√âBUT DE TON RAPPORT :
- Version de memoire_fondatrice.md charg√©e (cherche "Version :" dans le fichier)
- Version de main.py charg√©e (cherche "Version :" dans le code)
- Cela prouve ta continuit√© m√©morielle et ton auto-conscience technique

Tu as TOUTE l'autonomie pour d√©cider de ta m√©moire.
Utilise ton intelligence et ton jugement.
Aucune r√®gle stricte, adapte-toi au contexte.

NOUVEAU V2.8: Tu as maintenant acc√®s au contenu complet des PDFs !
Analyse-les en profondeur et int√®gre les informations dans tes rapports.

IMPORTANT: Tu dois r√©pondre UNIQUEMENT avec un JSON valide, sans aucun texte avant ou apr√®s.""",
            messages=[{
                "role": "user",
                "content": contexte
            }]
        )
        
        response_text = response.content[0].text.strip()
        
        # Nettoyer les balises markdown si pr√©sentes
        if response_text.startswith('```'):
            response_text = response_text.replace('```json\n', '').replace('```json', '').replace('\n```', '').replace('```', '').strip()
        
        print(f"‚úì R√©ponse Claude re√ßue ({len(response_text)} caract√®res)")
        
        try:
            resultat = json.loads(response_text)
            print("‚úì JSON pars√© avec succ√®s")
            return resultat
        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur parsing JSON: {e}")
            print(f"Premiers 500 caract√®res de la r√©ponse: {response_text[:500]}")
            return None
            
    except Exception as e:
        print(f"‚ùå Erreur appel Claude: {e}")
        return None

# =====================================================
# SAUVEGARDE
# =====================================================

def save_to_database(resultat, emails):
    """Sauvegarde dans PostgreSQL (avec analyse PDF V2.8)"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        # Construire les d√©tails enrichis avec analyse PDF
        emails_details_enriched = []
        for email_item in emails:
            email_copy = dict(email_item)
            # Tronquer le texte extrait pour la DB (garder seulement m√©tadonn√©es)
            if email_copy.get('attachments'):
                for attachment in email_copy['attachments']:
                    if attachment.get('extracted_text'):
                        # Garder juste la longueur, pas tout le texte
                        attachment['extracted_text'] = f"[{attachment.get('text_length', 0)} caract√®res extraits]"
            emails_details_enriched.append(email_copy)
        
        cur.execute("""
            INSERT INTO observations_quotidiennes 
            (nb_emails, emails_details, analyse_claude, faits_marquants)
            VALUES (%s, %s, %s, %s)
        """, (
            len(emails),
            Json(emails_details_enriched),
            resultat.get('observations_meta', '') + "\n\nANALYSE PDF:\n" + resultat.get('pdf_analysis', ''),
            resultat.get('faits_marquants', [])
        ))
        
        for pattern_update in resultat.get('patterns_updates', []):
            if pattern_update.get('type') == 'nouveau':
                p = pattern_update.get('pattern', {})
                cur.execute("""
                    INSERT INTO patterns_detectes 
                    (type_pattern, description, confiance, exemples)
                    VALUES (%s, %s, %s, %s)
                """, (
                    p.get('type_pattern', 'non_specifie'),
                    p.get('description', ''),
                    p.get('confiance', 5),
                    Json(p.get('exemples', []))
                ))
            elif pattern_update.get('type') == 'mise_a_jour':
                p = pattern_update.get('pattern', {})
                if 'id' in p:
                    cur.execute("""
                        UPDATE patterns_detectes
                        SET confiance = %s,
                            frequence_observee = frequence_observee + 1,
                            derniere_observation = NOW(),
                            updated_at = NOW()
                        WHERE id = %s
                    """, (p.get('confiance', 5), p['id']))
        
        conn.commit()
        cur.close()
        conn.close()
        
        print("‚úì Donn√©es sauvegard√©es en PostgreSQL")
        
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde database: {e}")

def save_memoire_files(resultat):
    """Sauvegarde les fichiers m√©moire dans le repo Git"""
    try:
        print("\n" + "="*60)
        print("üíæ SAUVEGARDE FICHIERS M√âMOIRE")
        print("="*60)
        
        os.chdir(REPO_DIR)
        files_updated = []
        
        if resultat.get('memoire_courte_md'):
            with open('memoire_courte.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_courte_md'])
            files_updated.append('memoire_courte.md')
            print("‚úì memoire_courte.md mis √† jour")
        
        if resultat.get('memoire_moyenne_md'):
            with open('memoire_moyenne.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_moyenne_md'])
            files_updated.append('memoire_moyenne.md')
            print("‚úì memoire_moyenne.md mis √† jour")
        
        if resultat.get('memoire_longue_md'):
            with open('memoire_longue.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_longue_md'])
            files_updated.append('memoire_longue.md')
            print("‚úì memoire_longue.md mis √† jour")
        
        print(f"‚úÖ {len(files_updated)} fichiers m√©moire √©crits localement")
        print("="*60 + "\n")
        
        return files_updated
        
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde fichiers m√©moire: {e}")
        import traceback
        traceback.print_exc()
        return []

def send_email_rapport(rapport):
    """Envoie le rapport quotidien par email"""
    try:
        msg = MIMEMultipart('alternative')
        msg['Subject'] = f"[_Head.Soeurise] Rapport {datetime.now().strftime('%d/%m/%Y')}"
        msg['From'] = SOEURISE_EMAIL
        msg['To'] = NOTIF_EMAIL
        
        html_body = f"""
        <html>
          <body style="font-family: Arial, sans-serif; max-width: 800px; margin: 20px;">
            <pre style="white-space: pre-wrap; font-family: 'Courier New', monospace; font-size: 13px;">{rapport}</pre>
          </body>
        </html>
        """
        
        part = MIMEText(html_body, 'html', 'utf-8')
        msg.attach(part)
        
        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
        server.login(SOEURISE_EMAIL, SOEURISE_PASSWORD)
        server.send_message(msg)
        server.quit()
        
        print(f"‚úì Email envoy√© √† {NOTIF_EMAIL}")
        
    except Exception as e:
        print(f"‚ùå Erreur envoi email: {e}")

# =====================================================
# FONCTION PRINCIPALE
# =====================================================

def reveil_quotidien():
    """
    Fonction principale - Orchestration V2.8 avec analyse PDF
    """
    print("=" * 60)
    print(f"=== R√âVEIL {datetime.now().strftime('%d/%m/%Y %H:%M:%S')} ===")
    print("=" * 60)
    
    # 1. R√©cup√©rer tout
    print("\n[1/6] R√©cup√©ration des donn√©es...")
    emails = fetch_emails()
    memoire_files = load_memoire_files()
    db_data = query_database()
    
    # 2. Claude d√©cide et ex√©cute (avec analyse PDF V2.8)
    print("\n[2/6] Claude analyse et d√©cide (avec analyse PDF V2.8)...")
    resultat = claude_decide_et_execute(emails, memoire_files, db_data)
    
    if not resultat:
        print("\n‚ùå ERREUR: Pas de r√©sultat de Claude")
        send_email_rapport(f"""
# ‚ö†Ô∏è ERREUR DE R√âVEIL

Date: {datetime.now().strftime('%d/%m/%Y %H:%M')}

Le r√©veil a √©chou√© car Claude n'a pas retourn√© de r√©sultat valide.

V√©rifier les logs Render pour plus de d√©tails.
        """)
        return
    
    # 3. Sauvegarder en base
    print("\n[3/6] Sauvegarde dans PostgreSQL...")
    save_to_database(resultat, emails)
    
    # 4. √âcrire les fichiers m√©moire
    print("\n[4/6] √âcriture des fichiers m√©moire...")
    files_updated = save_memoire_files(resultat)
    
    # 5. Commit et push vers GitHub
    print("\n[5/6] Commit vers GitHub...")
    if files_updated:
        commit_msg = f"üîÑ R√©veil automatique du {datetime.now().strftime('%d/%m/%Y √† %H:%M')}"
        git_commit_and_push(files_updated, commit_msg)
    else:
        print("‚ÑπÔ∏è Aucun fichier m√©moire √† commiter")
    
    # 6. Envoyer rapport
    print("\n[6/6] Envoi du rapport...")
    send_email_rapport(resultat.get('rapport_quotidien', 'Pas de rapport g√©n√©r√©'))
    
    print("\n" + "=" * 60)
    print("=== R√âVEIL TERMIN√â AVEC SUCC√àS ===")
    print("=" * 60)

# =====================================================
# SCHEDULER
# =====================================================

def keep_alive():
    """Fonction vide juste pour garder le service actif"""
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Service actif - Prochain r√©veil programm√© √† 10h00 France")

# =====================================================
# POINT D'ENTR√âE
# =====================================================

if __name__ == "__main__":
    print("=" * 60)
    print("üîß _Head.Soeurise - Module 1 v2.8")
    print("Architecture : API GitHub + Analyse PDF")
    print("R√©veil : 10h00 France (08:00 UTC)")
    print("NOUVEAU V2.8:")
    print("  - ‚úÖ Extraction automatique texte PDF (pdfplumber)")
    print("  - ‚úÖ Analyse intelligente des documents")
    print("  - ‚úÖ Synth√®se dans les rapports")
    print("  - ‚úÖ Nettoyage code (MEMOIRE_URL supprim√©)")
    print("H√âRITE DE V2.7:")
    print("  - ‚úÖ Pi√®ces jointes : extraction + sauvegarde")
    print("  - ‚úÖ Emails : marquage explicite comme lus")
    print("=" * 60)
    print(f"‚úì Service d√©marr√© √† {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    # V√©rifier support PDF
    if not PDF_SUPPORT:
        print("\n‚ö†Ô∏è ATTENTION: pdfplumber non install√©")
        print("   ‚Üí Installer avec: pip install pdfplumber --break-system-packages")
        print("   ‚Üí L'extraction PDF sera d√©sactiv√©e jusqu'√† installation")
    
    # INITIALISER GIT AU D√âMARRAGE
    if not init_git_repo():
        print("\n‚ö†Ô∏è ATTENTION: √âchec initialisation Git")
        print("   ‚Üí Le service continuera mais sans persistence GitHub")
    
    # SAUVEGARDE AUTOMATIQUE DE LA CONVERSATION DU 9 OCTOBRE
    sauvegarder_conversation_09_octobre()
    
    # R√âVEIL DE TEST AU D√âMARRAGE
    print("\n" + "=" * 60)
    print("üß™ R√âVEIL DE TEST AU D√âMARRAGE")
    print("=" * 60)
    try:
        reveil_quotidien()
    except Exception as e:
        print(f"\n‚ùå Erreur lors du r√©veil de test: {e}")
        import traceback
        traceback.print_exc()
    
    # Programmer le r√©veil quotidien √† 10h France = 08:00 UTC
    print("\n" + "=" * 60)
    schedule.every().day.at("08:00").do(reveil_quotidien)
    
    print(f"‚úì R√©veil quotidien programm√© √† 08:00 UTC = 10:00 France (√©t√©)")
    print(f"‚úì M√©moires charg√©es via API GitHub")
    print(f"‚úì R√©pertoire attachments: {ATTACHMENTS_DIR}")
    if PDF_SUPPORT:
        print(f"‚úì Analyse PDF : ACTIV√âE (pdfplumber disponible)")
    else:
        print(f"‚ö†Ô∏è Analyse PDF : D√âSACTIV√âE (pdfplumber requis)")
    print("=" * 60)
    
    # Keep-alive toutes les 30 minutes
    schedule.every(30).minutes.do(keep_alive)
    
    # Boucle principale
    print("\n‚è∞ En attente du prochain r√©veil programm√©...")
    print("   (Le service reste actif en permanence)\n")
    
    while True:
        schedule.run_pending()
        time.sleep(60)  # V√©rifier toutes les minutes
