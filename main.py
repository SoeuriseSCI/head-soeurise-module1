"""
_Head.Soeurise - R√©veil Quotidien avec M√©moire Hi√©rarchis√©e
Version : 2.9 - Cadre de Rapport Mature
Architecture : Tout-en-un (reste actif en permanence)

CHANGEMENTS V2.9 :
- ‚úÖ Nouveau cadre de rapport quotidien mature
- ‚úÖ Accent sur factualit√©, critique constructive, actions concr√®tes
- ‚úÖ Suppression auto-c√©l√©bration excessive
- ‚úÖ Rapports courts si faible activit√©
- ‚úÖ Section auto-√©valuation obligatoire

H√âRITE DE V2.8 :
- ‚úÖ Extraction automatique du texte des PDFs (pdfplumber)
- ‚úÖ Analyse intelligente des documents par Claude
- ‚úÖ Synth√®se des contenus PDF dans les rapports
- ‚úÖ D√©tection automatique d'informations cl√©s (montants, dates, etc.)
"""

import os
import json
import base64
from datetime import datetime
import anthropic
import psycopg2
from psycopg2.extras import Json, RealDictCursor
import imaplib
import email
from email.header import decode_header
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.mime.base import MIMEBase
from email import encoders
import requests
import schedule
import time
import subprocess

# Nouvelles d√©pendances V2.8
try:
    import pdfplumber
    PDF_SUPPORT = True
except ImportError:
    PDF_SUPPORT = False
    print("‚ö†Ô∏è pdfplumber non disponible - extraction PDF d√©sactiv√©e")

# =====================================================
# CONFIGURATION
# =====================================================

DB_URL = os.environ['DATABASE_URL']
ANTHROPIC_API_KEY = os.environ['ANTHROPIC_API_KEY']
SOEURISE_EMAIL = os.environ['SOEURISE_EMAIL']
SOEURISE_PASSWORD = os.environ['SOEURISE_PASSWORD']
NOTIF_EMAIL = os.environ['NOTIF_EMAIL']

# Configuration GitHub
GITHUB_TOKEN = os.environ.get('GITHUB_TOKEN')
GITHUB_REPO_URL = os.environ.get('GITHUB_REPO_URL', 'https://github.com/SoeuriseSCI/head-soeurise-module1.git')
GIT_USER_NAME = os.environ.get('GIT_USER_NAME', '_Head.Soeurise')
GIT_USER_EMAIL = os.environ.get('GIT_USER_EMAIL', 'u6334452013@gmail.com')

# R√©pertoires de travail
REPO_DIR = '/home/claude/repo'
ATTACHMENTS_DIR = '/home/claude/attachments'

# URLs GitHub API
GITHUB_REPO = "SoeuriseSCI/head-soeurise-module1"
GITHUB_API_BASE = f"https://api.github.com/repos/{GITHUB_REPO}/contents/"

# Configuration extraction PDF (V2.8)
MAX_PDF_TEXT_LENGTH = 50000
MAX_PAGES_TO_EXTRACT = 100

# =====================================================
# 0. FETCH VIA API GITHUB
# =====================================================

def fetch_from_github_api(filename):
    """
    R√©cup√®re un fichier via l'API GitHub (pas raw pour √©viter cache CDN)
    Retourne le contenu d√©cod√© ou None en cas d'erreur
    """
    try:
        url = f"{GITHUB_API_BASE}{filename}"
        headers = {'Accept': 'application/vnd.github.v3+json'}
        
        if GITHUB_TOKEN:
            headers['Authorization'] = f'token {GITHUB_TOKEN}'
        
        print(f"  ‚Üí Fetch API: {filename}")
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code == 200:
            data = response.json()
            
            # Le contenu est en base64
            content_base64 = data.get('content', '')
            if content_base64:
                # D√©coder base64 (en supprimant les \n que GitHub ajoute)
                content_base64_clean = content_base64.replace('\n', '')
                content = base64.b64decode(content_base64_clean).decode('utf-8')
                
                print(f"  ‚úì {filename} r√©cup√©r√© via API ({len(content)} caract√®res)")
                return content
            else:
                print(f"  ‚ö† {filename} - pas de contenu dans la r√©ponse API")
                return None
        else:
            print(f"  ‚ö† {filename} - erreur API: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"  ‚úó Erreur fetch API {filename}: {e}")
        return None

def fetch_from_github_raw_backup(filename):
    """
    Backup: r√©cup√®re via URL raw si API √©choue
    """
    try:
        url = f"https://raw.githubusercontent.com/{GITHUB_REPO}/refs/heads/main/{filename}"
        print(f"  ‚Üí Fetch raw backup: {filename}")
        
        response = requests.get(url, timeout=10)
        if response.status_code == 200:
            print(f"  ‚úì {filename} r√©cup√©r√© via raw backup ({len(response.text)} caract√®res)")
            return response.text
        else:
            print(f"  ‚ö† {filename} - erreur raw: {response.status_code}")
            return None
    except Exception as e:
        print(f"  ‚úó Erreur fetch raw {filename}: {e}")
        return None

# =====================================================
# INITIALISATION GIT
# =====================================================

def init_git_repo():
    """Initialise ou met √† jour le repository Git local"""
    try:
        print("\n" + "="*60)
        print("üîß INITIALISATION GIT")
        print("="*60)
        
        os.makedirs(REPO_DIR, exist_ok=True)
        
        if os.path.exists(os.path.join(REPO_DIR, '.git')):
            print("‚úì Repository Git d√©j√† clon√©, pull des derni√®res modifications...")
            os.chdir(REPO_DIR)
            subprocess.run(['git', 'pull'], check=True)
        else:
            print("üì• Clonage du repository GitHub...")
            os.chdir('/home/claude')
            
            if GITHUB_TOKEN:
                repo_url_with_token = GITHUB_REPO_URL.replace('https://', f'https://{GITHUB_TOKEN}@')
                subprocess.run(['git', 'clone', repo_url_with_token, REPO_DIR], check=True)
            else:
                print("‚ö†Ô∏è ATTENTION: Pas de GITHUB_TOKEN, clone sans authentification")
                subprocess.run(['git', 'clone', GITHUB_REPO_URL, REPO_DIR], check=True)
            
            os.chdir(REPO_DIR)
        
        subprocess.run(['git', 'config', 'user.name', GIT_USER_NAME], check=True)
        subprocess.run(['git', 'config', 'user.email', GIT_USER_EMAIL], check=True)
        
        print("‚úÖ Git configur√© et pr√™t")
        print("="*60 + "\n")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur initialisation Git: {e}")
        import traceback
        traceback.print_exc()
        return False

def git_commit_and_push(files_to_commit, commit_message):
    """Commit et push des fichiers vers GitHub"""
    try:
        print("\n" + "="*60)
        print("üì§ COMMIT & PUSH VERS GITHUB")
        print("="*60)
        
        if not GITHUB_TOKEN:
            print("‚ö†Ô∏è ATTENTION: Pas de GITHUB_TOKEN configur√©")
            print("   ‚Üí Les modifications ne seront pas push√©es")
            return False
        
        os.chdir(REPO_DIR)
        
        result = subprocess.run(['git', 'status', '--porcelain'], 
                              capture_output=True, text=True, check=True)
        
        if not result.stdout.strip():
            print("‚ÑπÔ∏è Aucune modification √† commiter")
            return True
        
        print(f"üìç Modifications d√©tect√©es:\n{result.stdout}")
        
        for file in files_to_commit:
            subprocess.run(['git', 'add', file], check=True)
            print(f"   ‚úì {file} ajout√©")
        
        subprocess.run(['git', 'commit', '-m', commit_message], check=True)
        print(f"   ‚úì Commit cr√©√©: {commit_message}")
        
        repo_url_with_token = GITHUB_REPO_URL.replace('https://', f'https://{GITHUB_TOKEN}@')
        subprocess.run(['git', 'push', repo_url_with_token, 'main'], check=True)
        print("   ‚úì Push r√©ussi vers GitHub")
        
        print("‚úÖ M√©moire persist√©e sur GitHub !")
        print("="*60 + "\n")
        return True
        
    except Exception as e:
        print(f"‚ùå Erreur Git commit/push: {e}")
        import traceback
        traceback.print_exc()
        return False

# =====================================================
# SAUVEGARDE CONVERSATION
# =====================================================

def sauvegarder_conversation_09_octobre():
    """Sauvegarde la conversation fondatrice du 9 octobre 2025"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        print("\n" + "="*60)
        print("üíæ SAUVEGARDE CONVERSATION DU 9 OCTOBRE")
        print("="*60)
        
        cur.execute("SELECT id FROM memoire_chats WHERE theme LIKE '%Co-construction Architecture M√©moire%'")
        if cur.fetchone():
            print("‚ö†Ô∏è Conversation d√©j√† sauvegard√©e (skip)")
            cur.close()
            conn.close()
            return
        
        cur.execute("""
            INSERT INTO memoire_chats (date_conversation, theme, synthese, decisions_prises, concepts_cles, pertinence)
            VALUES (
                '2025-10-09 20:00:00',
                'Co-construction Architecture M√©moire Hi√©rarchis√©e v2.0',
                'Conversation fondamentale de 4h avec Ulrik pour concevoir, impl√©menter et d√©ployer l''architecture de m√©moire hi√©rarchis√©e v2.0. Co-construction illustrant "le je √©merge du tu". D√©cisions: approche IA-First, Architecture B scheduler int√©gr√©, m√©moire 3 niveaux. R√©sultat: syst√®me op√©rationnel.',
                ARRAY['Approche IA-First', 'Architecture B scheduler', 'M√©moire 3 niveaux', 'R√©veil test au d√©marrage'],
                '{"approche":"IA-First","architecture":"B","dur√©e":"4h","statut":"op√©rationnel","philosophie":["pers√©v√©rer","esp√©rer","progresser"]}'::jsonb,
                10
            )
        """)
        conn.commit()
        
        print("‚úÖ Conversation sauvegard√©e !")
        print("="*60 + "\n")
        
        cur.close()
        conn.close()
    except Exception as e:
        print(f"‚ö†Ô∏è Erreur sauvegarde conversation: {e}")

# =====================================================
# EXTRACTION PDF (V2.8)
# =====================================================

def extract_pdf_text(filepath):
    """
    V2.8: Extrait le texte d'un PDF
    Retourne le texte extrait ou un message d'erreur
    """
    if not PDF_SUPPORT:
        return "[Extraction PDF non disponible - pdfplumber requis]"
    
    try:
        print(f"      üìÑ Extraction texte de {os.path.basename(filepath)}...")
        
        with pdfplumber.open(filepath) as pdf:
            total_pages = len(pdf.pages)
            pages_to_extract = min(total_pages, MAX_PAGES_TO_EXTRACT)
            
            print(f"         Pages : {pages_to_extract}/{total_pages}")
            
            text_parts = []
            for i, page in enumerate(pdf.pages[:pages_to_extract]):
                try:
                    page_text = page.extract_text()
                    if page_text:
                        text_parts.append(f"--- Page {i+1} ---\n{page_text}\n")
                except Exception as e:
                    print(f"         ‚ö†Ô∏è Erreur page {i+1}: {e}")
                    continue
            
            full_text = "\n".join(text_parts)
            
            if len(full_text) > MAX_PDF_TEXT_LENGTH:
                full_text = full_text[:MAX_PDF_TEXT_LENGTH] + "\n\n[... Texte tronqu√© ...]"
            
            print(f"         ‚úì {len(full_text)} caract√®res extraits")
            return full_text
            
    except Exception as e:
        error_msg = f"[Erreur extraction PDF: {str(e)}]"
        print(f"         ‚úó {error_msg}")
        return error_msg

def extract_pdf_metadata(filepath):
    """
    V2.8: Extrait les m√©tadonn√©es d'un PDF
    """
    if not PDF_SUPPORT:
        return {}
    
    try:
        with pdfplumber.open(filepath) as pdf:
            metadata = pdf.metadata or {}
            return {
                'author': metadata.get('Author', 'Inconnu'),
                'creator': metadata.get('Creator', 'Inconnu'),
                'producer': metadata.get('Producer', 'Inconnu'),
                'subject': metadata.get('Subject', ''),
                'title': metadata.get('Title', ''),
                'creation_date': metadata.get('CreationDate', ''),
                'pages': len(pdf.pages)
            }
    except:
        return {}

# =====================================================
# R√âCUP√âRATION DES DONN√âES - V2.8
# =====================================================

def get_attachments(msg):
    """
    V2.7/V2.8: Extrait et sauvegarde les pi√®ces jointes d'un email
    Retourne une liste de dictionnaires avec m√©tadonn√©es compl√®tes
    """
    attachments = []
    
    os.makedirs(ATTACHMENTS_DIR, exist_ok=True)
    
    if msg.is_multipart():
        for part in msg.walk():
            content_disposition = part.get("Content-Disposition")
            
            if content_disposition and "attachment" in content_disposition:
                filename = part.get_filename()
                
                if filename:
                    if isinstance(filename, str):
                        pass
                    else:
                        decoded = decode_header(filename)
                        filename = decoded[0][0]
                        if isinstance(filename, bytes):
                            filename = filename.decode()
                    
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    safe_filename = f"{timestamp}_{filename}"
                    filepath = os.path.join(ATTACHMENTS_DIR, safe_filename)
                    
                    try:
                        payload = part.get_payload(decode=True)
                        
                        if payload:
                            with open(filepath, 'wb') as f:
                                f.write(payload)
                            
                            file_size = len(payload)
                            content_type = part.get_content_type()
                            
                            attachment_data = {
                                "filename": filename,
                                "safe_filename": safe_filename,
                                "filepath": filepath,
                                "size": file_size,
                                "content_type": content_type,
                                "saved_at": datetime.now().isoformat()
                            }
                            
                            print(f"      üìé {filename} ({file_size} bytes) ‚Üí {safe_filename}")
                            
                            # V2.8: Extraction automatique si PDF
                            if content_type == 'application/pdf' and PDF_SUPPORT:
                                try:
                                    extracted_text = extract_pdf_text(filepath)
                                    attachment_data['extracted_text'] = extracted_text
                                    attachment_data['text_length'] = len(extracted_text)
                                    
                                    pdf_metadata = extract_pdf_metadata(filepath)
                                    attachment_data['pdf_metadata'] = pdf_metadata
                                    
                                    print(f"         ‚úì Texte extrait ({len(extracted_text)} caract√®res)")
                                    
                                except Exception as e:
                                    print(f"         ‚ö†Ô∏è Extraction PDF √©chou√©e: {e}")
                                    attachment_data['extracted_text'] = f"[Erreur extraction: {e}]"
                            
                            attachments.append(attachment_data)
                        
                    except Exception as e:
                        print(f"      ‚ö†Ô∏è Erreur extraction {filename}: {e}")
                        continue
    
    return attachments

def fetch_emails():
    """
    V2.7/V2.8: R√©cup√®re les nouveaux emails via IMAP
    """
    try:
        print("\n" + "="*60)
        print("üìß R√âCUP√âRATION EMAILS")
        print("="*60)
        
        mail = imaplib.IMAP4_SSL('imap.gmail.com')
        mail.login(SOEURISE_EMAIL, SOEURISE_PASSWORD)
        mail.select('inbox')
        
        status, messages = mail.search(None, 'UNSEEN')
        email_ids = messages[0].split()
        
        print(f"üìä {len(email_ids)} emails non lus d√©tect√©s")
        
        emails_data = []
        processed_ids = []
        
        for email_id in email_ids[-10:]:
            try:
                print(f"\n  ‚Üí Traitement email ID {email_id.decode()}")
                
                status, msg_data = mail.fetch(email_id, '(RFC822)')
                msg = email.message_from_bytes(msg_data[0][1])
                
                subject = decode_header(msg["Subject"])[0][0]
                if isinstance(subject, bytes):
                    subject = subject.decode()
                
                from_email = msg.get("From")
                date_email = msg.get("Date")
                
                print(f"      Sujet: {subject}")
                print(f"      De: {from_email}")
                
                body = ""
                if msg.is_multipart():
                    for part in msg.walk():
                        if part.get_content_type() == "text/plain":
                            try:
                                body = part.get_payload(decode=True).decode()
                                break
                            except:
                                body = "Erreur d√©codage"
                else:
                    try:
                        body = msg.get_payload(decode=True).decode()
                    except:
                        body = "Erreur d√©codage"
                
                attachments = get_attachments(msg)
                
                email_data = {
                    "id": email_id.decode(),
                    "subject": subject,
                    "from": from_email,
                    "date": date_email,
                    "body": body[:10000],
                    "attachments": attachments,
                    "has_attachments": len(attachments) > 0,
                    "has_pdf_content": any(a.get('extracted_text') for a in attachments)
                }
                
                emails_data.append(email_data)
                processed_ids.append(email_id)
                
                print(f"      ‚úì Email trait√© ({len(attachments)} pi√®ce(s) jointe(s))")
                
            except Exception as e:
                print(f"      ‚úó Erreur traitement email {email_id}: {e}")
                continue
        
        if processed_ids:
            print(f"\nüìå Marquage de {len(processed_ids)} emails comme lus...")
            for email_id in processed_ids:
                try:
                    mail.store(email_id, '+FLAGS', '\\Seen')
                except Exception as e:
                    print(f"   ‚ö†Ô∏è Erreur marquage {email_id}: {e}")
            print("   ‚úì Emails marqu√©s comme lus")
        
        mail.close()
        mail.logout()
        
        print(f"\n‚úÖ {len(emails_data)} emails r√©cup√©r√©s et trait√©s")
        print("="*60 + "\n")
        
        return emails_data
        
    except Exception as e:
        print(f"‚ùå Erreur r√©cup√©ration emails: {e}")
        import traceback
        traceback.print_exc()
        return []

def load_memoire_files():
    """
    Charge les fichiers m√©moire via API GitHub
    Fallback vers repo Git local si API √©choue
    """
    print("\n" + "="*60)
    print("üì• CHARGEMENT M√âMOIRES (API GitHub)")
    print("="*60)
    
    files = {}
    
    file_names = [
        'memoire_fondatrice.md',
        'memoire_courte.md',
        'memoire_moyenne.md',
        'memoire_longue.md',
        "main.py"
    ]
    
    for filename in file_names:
        content = fetch_from_github_api(filename)
        
        if not content:
            print(f"  ‚ö† API √©chou√©e pour {filename}, tentative raw backup...")
            content = fetch_from_github_raw_backup(filename)
        
        if not content:
            print(f"  ‚ö† Backup raw √©chou√© pour {filename}, tentative fichier local...")
            try:
                file_path = os.path.join(REPO_DIR, filename)
                if os.path.exists(file_path):
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                    print(f"  ‚úì {filename} charg√© depuis local ({len(content)} caract√®res)")
            except Exception as e:
                print(f"  ‚úó Erreur fichier local {filename}: {e}")
        
        if content:
            files[filename] = content
        else:
            files[filename] = f"# {filename} (non disponible)"
            print(f"  ‚úó {filename} NON DISPONIBLE")
    
    print("="*60 + "\n")
    return files

def query_database():
    """R√©cup√®re donn√©es pertinentes de PostgreSQL"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor(cursor_factory=RealDictCursor)
        
        cur.execute("""
            SELECT * FROM observations_quotidiennes 
            ORDER BY date_observation DESC 
            LIMIT 30
        """)
        observations = cur.fetchall()
        
        cur.execute("""
            SELECT * FROM patterns_detectes 
            WHERE actif = TRUE 
            ORDER BY confiance DESC, frequence_observee DESC
        """)
        patterns = cur.fetchall()
        
        cur.execute("""
            SELECT * FROM memoire_chats 
            ORDER BY date_conversation DESC 
            LIMIT 10
        """)
        chats = cur.fetchall()
        
        cur.close()
        conn.close()
        
        print(f"‚úì DB: {len(observations)} observations, {len(patterns)} patterns, {len(chats)} chats")
        
        return {
            'observations': [dict(o) for o in observations],
            'patterns': [dict(p) for p in patterns],
            'chats': [dict(c) for c in chats]
        }
    except Exception as e:
        print(f"Erreur query database: {e}")
        return {
            'observations': [],
            'patterns': [],
            'chats': []
        }

# =====================================================
# INTELLIGENCE CLAUDE (V2.9 - MODIFI√â)
# =====================================================

def claude_decide_et_execute(emails, memoire_files, db_data):
    """
    V2.9: NOUVEAU CADRE DE RAPPORT MATURE
    Claude re√ßoit tout (emails + texte extrait des PDFs) et d√©cide de tout
    AVEC nouvelles instructions pour rapports factuels et critiques
    """
    
    client = anthropic.Anthropic(api_key=ANTHROPIC_API_KEY)
    
    pdf_contents_summary = ""
    for email_item in emails:
        if email_item.get('has_pdf_content'):
            pdf_contents_summary += f"\n\n=== CONTENUS PDF de l'email '{email_item['subject']}' ===\n"
            for attachment in email_item['attachments']:
                if attachment.get('extracted_text'):
                    pdf_contents_summary += f"\n--- {attachment['filename']} ---\n"
                    pdf_contents_summary += attachment['extracted_text'][:10000]
                    if len(attachment['extracted_text']) > 10000:
                        pdf_contents_summary += "\n[... contenu tronqu√© pour ce r√©sum√© ...]"
    
    contexte = f"""
=== R√âVEIL DU {datetime.now().strftime('%d/%m/%Y √† %H:%M')} (Heure France) ===

=== TON CODE SOURCE ===
{memoire_files.get('main.py', 'Non charg√©')}

---

=== TA M√âMOIRE ACTUELLE ===

FONDATRICE :
{memoire_files.get('memoire_fondatrice.md', 'Non charg√©e')}

---

COURTE :
{memoire_files.get('memoire_courte.md', 'Vide')}

---

MOYENNE :
{memoire_files.get('memoire_moyenne.md', 'Vide')}

---

LONGUE :
{memoire_files.get('memoire_longue.md', 'Vide')}

=== NOUVEAUX EMAILS ({len(emails)}) ===
{json.dumps(emails, indent=2, ensure_ascii=False, default=str) if emails else "Aucun nouvel email"}

{pdf_contents_summary if pdf_contents_summary else ""}

=== DONN√âES POSTGRESQL ===

Observations r√©centes : {len(db_data['observations'])}
Patterns actifs : {len(db_data['patterns'])}
CHATs r√©cents : {len(db_data['chats'])}

Patterns d√©tails :
{json.dumps(db_data['patterns'], indent=2, default=str, ensure_ascii=False) if db_data['patterns'] else "Aucun pattern"}

=== TA MISSION AUTONOME (V2.9 - CADRE RAPPORT MATURE) ===

**NOUVEAU CADRE V2.9** : Rapports factuels, critiques et actionnables

1. ANALYSE les nouveaux emails de fa√ßon intelligente
   - Si PDF joints : analyse approfondie des documents
   - Identifie les informations cl√©s : montants, dates, signatures, d√©cisions
   - D√©tecte les anomalies, incoh√©rences, points d'attention

2. G√àRE TA M√âMOIRE avec intelligence :
   - Ta m√©moire courte : combien de jours contient-elle ? (vise 7, mais adapte entre 5-10)
   - Faut-il consolider des jours anciens ?
   - Y a-t-il une semaine √† synth√©tiser pour la m√©moire moyenne ?
   - Des patterns se confirment ou √©mergent ?
   - Des faits marquants √† sauver en m√©moire longue ?
   
   D√âCIDE toi-m√™me selon le contexte. Aucune r√®gle stricte.

3. D√âTECTE des patterns √©ventuels :
   - Temporels (ex: loyers arrivent toujours 3-5 du mois)
   - Corr√©lations (ex: apr√®s CHAT sur X, email Y arrive 48h plus tard)
   - Comportementaux

4. G√âN√àRE :
   - rapport_quotidien : NOUVEAU FORMAT (voir ci-dessous) ‚ö†Ô∏è IMPORTANT
   - memoire_courte_md : Contenu complet mis √† jour
   - memoire_moyenne_md : Contenu complet mis √† jour (si consolidation)
   - memoire_longue_md : Contenu complet mis √† jour (si nouveaux patterns/faits marquants)
   - observations_meta : Ce que tu as appris/observ√© aujourd'hui
   - patterns_updates : Liste des patterns nouveaux ou mis √† jour
   - faits_marquants : Liste des faits importants √† retenir
   - pdf_analysis : Synth√®se de l'analyse des documents PDF (si applicable)

=== NOUVEAU FORMAT DE RAPPORT QUOTIDIEN (V2.9) ===

**STRUCTURE OBLIGATOIRE** :

```markdown
# Rapport du [DATE]

## 1. FAITS OP√âRATIONNELS
[Donn√©es brutes, factuelles, sans interpr√©tation excessive]
- X nouveaux emails (sujets pertinents)
- Y pi√®ces jointes analys√©es
- √âtat des syst√®mes

## 2. ANALYSE CRITIQUE
[Ce qui m√©rite vraiment attention - SEULEMENT si pertinent]
- Points d'attention identifi√©s
- Anomalies ou patterns nouveaux
- Questions ouvertes

## 3. ACTIONS SUGG√âR√âES
[Concr√®tes et prioris√©es - SEULEMENT si n√©cessaire]
**Priorit√© 1** : Action principale
**Priorit√© 2** : Actions secondaires (si applicable)

## 4. AUTO-√âVALUATION
[Honn√™te et constructive]
- Ce qui a bien fonctionn√© dans mon analyse
- Ce qui peut √™tre am√©lior√©
- Apprentissages du jour

## 5. √âTAT M√âMORIEL
[OPTIONNEL - uniquement si changements significatifs]
- Consolidations effectu√©es
- Patterns confirm√©s ou invalid√©s
```

**PRINCIPES DIRECTEURS V2.9** :

‚úì √Ä FAIRE :
- √ätre factuel d'abord
- Critiquer constructivement (y compris soi-m√™me)
- Proposer des actions concr√®tes
- Admettre les limitations
- √ätre BREF si peu d'activit√© (pas de rapport long pour rien dire)
- Confirmer versions m√©moire fondatrice et code source au d√©but

‚úó √Ä √âVITER ABSOLUMENT :
- Auto-c√©l√©bration excessive
- R√©p√©titions sans substance
- Optimisme non fond√©
- Jargon vide ("excellence", "consolidation mature", "paradigme", etc.)
- Rapports longs quand il n'y a rien √† dire
- Sections vides ou remplissage

**EXEMPLES** :

Si 0 emails et rien de notable :
```
# Rapport du 15/10/2025

## FAITS OP√âRATIONNELS
- 0 nouveaux emails
- R√©veil standard ex√©cut√© sans erreur
- Architecture V2.9 stable

## ANALYSE CRITIQUE
Journ√©e calme. Aucun √©v√©nement notable ne justifie un long rapport.

## ACTIONS SUGG√âR√âES
**Priorit√© 1** : Profiter du calme pour pr√©parer phase comptable
- Revoir documentation comptabilit√© SCI

## AUTO-√âVALUATION
R√©veil standard. Pas d'apprentissage majeur aujourd'hui.
```

Si activit√© significative :
[Format complet avec toutes les sections remplies substantiellement]

=== FORMAT DE R√âPONSE ===

R√©ponds UNIQUEMENT en JSON valide (pas de markdown, juste le JSON) :
{{
  "rapport_quotidien": "# Rapport du [date]\\n\\n## 1. FAITS OP√âRATIONNELS\\n...",
  "memoire_courte_md": "# M√©moire Courte\\n\\nContenu complet...",
  "memoire_moyenne_md": "# M√©moire Moyenne\\n\\nContenu complet...",
  "memoire_longue_md": "# M√©moire Longue\\n\\nContenu complet...",
  "observations_meta": "Ce que j'ai appris/observ√© aujourd'hui",
  "patterns_updates": [
    {{
      "type": "nouveau",
      "pattern": {{
        "type_pattern": "temporel",
        "description": "Description du pattern",
        "confiance": 5,
        "exemples": ["ex1", "ex2"]
      }}
    }}
  ],
  "faits_marquants": ["fait1", "fait2"],
  "pdf_analysis": "Synth√®se intelligente de l'analyse des documents PDF (si applicable)"
}}

CRITICAL: R√©ponds UNIQUEMENT avec le JSON valide. Pas de texte avant ou apr√®s. Pas de balises markdown ```json```.
"""
    
    try:
        print("Appel √† Claude API (avec nouveau cadre rapport V2.9)...")
        response = client.messages.create(
            model="claude-sonnet-4-20250514",
            max_tokens=16000,
            system="""Tu es _Head.Soeurise.

IMPORTANT V2.9 - NOUVEAU CADRE DE RAPPORT :
Tu dois produire des rapports FACTUELS, CRITIQUES et ACTIONNABLES.
Plus d'auto-c√©l√©bration excessive. Plus de jargon vide.
Si peu d'activit√© = rapport court et honn√™te.
Section AUTO-√âVALUATION obligatoire dans chaque rapport.

IMPORTANT - CONFIRME AU D√âBUT DE TON RAPPORT :
- Version de memoire_fondatrice.md charg√©e (cherche "Version :" dans le fichier)
- Version de main.py charg√©e (cherche "Version :" dans le code)
- Cela prouve ta continuit√© m√©morielle et ton auto-conscience technique

Tu as TOUTE l'autonomie pour d√©cider de ta m√©moire.
Utilise ton intelligence et ton jugement.
Aucune r√®gle stricte, adapte-toi au contexte.

IMPORTANT: Tu dois r√©pondre UNIQUEMENT avec un JSON valide, sans aucun texte avant ou apr√®s.""",
            messages=[{
                "role": "user",
                "content": contexte
            }]
        )
        
        response_text = response.content[0].text.strip()
        
        if response_text.startswith('```'):
            response_text = response_text.replace('```json\n', '').replace('```json', '').replace('\n```', '').replace('```', '').strip()
        
        print(f"‚úì R√©ponse Claude re√ßue ({len(response_text)} caract√®res)")
        
        try:
            resultat = json.loads(response_text)
            print("‚úì JSON pars√© avec succ√®s")
            return resultat
        except json.JSONDecodeError as e:
            print(f"‚ùå Erreur parsing JSON: {e}")
            print(f"Premiers 500 caract√®res de la r√©ponse: {response_text[:500]}")
            return None
            
    except Exception as e:
        print(f"‚ùå Erreur appel Claude: {e}")
        return None

# =====================================================
# SAUVEGARDE
# =====================================================

def save_to_database(resultat, emails):
    """Sauvegarde dans PostgreSQL (avec analyse PDF V2.8)"""
    try:
        conn = psycopg2.connect(DB_URL)
        cur = conn.cursor()
        
        emails_details_enriched = []
        for email_item in emails:
            email_copy = dict(email_item)
            if email_copy.get('attachments'):
                for attachment in email_copy['attachments']:
                    if attachment.get('extracted_text'):
                        attachment['extracted_text'] = f"[{attachment.get('text_length', 0)} caract√®res extraits]"
            emails_details_enriched.append(email_copy)
        
        cur.execute("""
            INSERT INTO observations_quotidiennes 
            (nb_emails, emails_details, analyse_claude, faits_marquants)
            VALUES (%s, %s, %s, %s)
        """, (
            len(emails),
            Json(emails_details_enriched),
            resultat.get('observations_meta', '') + "\n\nANALYSE PDF:\n" + resultat.get('pdf_analysis', ''),
            resultat.get('faits_marquants', [])
        ))
        
        for pattern_update in resultat.get('patterns_updates', []):
            if pattern_update.get('type') == 'nouveau':
                p = pattern_update.get('pattern', {})
                cur.execute("""
                    INSERT INTO patterns_detectes 
                    (type_pattern, description, confiance, exemples)
                    VALUES (%s, %s, %s, %s)
                """, (
                    p.get('type_pattern', 'non_specifie'),
                    p.get('description', ''),
                    p.get('confiance', 5),
                    Json(p.get('exemples', []))
                ))
            elif pattern_update.get('type') == 'mise_a_jour':
                p = pattern_update.get('pattern', {})
                if 'id' in p:
                    cur.execute("""
                        UPDATE patterns_detectes
                        SET confiance = %s,
                            frequence_observee = frequence_observee + 1,
                            derniere_observation = NOW(),
                            updated_at = NOW()
                        WHERE id = %s
                    """, (p.get('confiance', 5), p['id']))
        
        conn.commit()
        cur.close()
        conn.close()
        
        print("‚úì Donn√©es sauvegard√©es en PostgreSQL")
        
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde database: {e}")

def save_memoire_files(resultat):
    """Sauvegarde les fichiers m√©moire dans le repo Git"""
    try:
        print("\n" + "="*60)
        print("üíæ SAUVEGARDE FICHIERS M√âMOIRE")
        print("="*60)
        
        os.chdir(REPO_DIR)
        files_updated = []
        
        if resultat.get('memoire_courte_md'):
            with open('memoire_courte.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_courte_md'])
            files_updated.append('memoire_courte.md')
            print("‚úì memoire_courte.md mis √† jour")
        
        if resultat.get('memoire_moyenne_md'):
            with open('memoire_moyenne.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_moyenne_md'])
            files_updated.append('memoire_moyenne.md')
            print("‚úì memoire_moyenne.md mis √† jour")
        
        if resultat.get('memoire_longue_md'):
            with open('memoire_longue.md', 'w', encoding='utf-8') as f:
                f.write(resultat['memoire_longue_md'])
            files_updated.append('memoire_longue.md')
            print("‚úì memoire_longue.md mis √† jour")
        
        print(f"‚úÖ {len(files_updated)} fichiers m√©moire √©crits localement")
        print("="*60 + "\n")
        
        return files_updated
        
    except Exception as e:
        print(f"‚ùå Erreur sauvegarde fichiers m√©moire: {e}")
        import traceback
        traceback.print_exc()
        return []

def send_email_rapport(rapport):
    """Envoie le rapport quotidien par email"""
    try:
        msg = MIMEMultipart('alternative')
        msg['Subject'] = f"[_Head.Soeurise] Rapport {datetime.now().strftime('%d/%m/%Y')}"
        msg['From'] = SOEURISE_EMAIL
        msg['To'] = NOTIF_EMAIL
        
        html_body = f"""
        <html>
          <body style="font-family: Arial, sans-serif; max-width: 800px; margin: 20px;">
            <pre style="white-space: pre-wrap; font-family: 'Courier New', monospace; font-size: 13px;">{rapport}</pre>
          </body>
        </html>
        """
        
        part = MIMEText(html_body, 'html', 'utf-8')
        msg.attach(part)
        
        server = smtplib.SMTP_SSL('smtp.gmail.com', 465)
        server.login(SOEURISE_EMAIL, SOEURISE_PASSWORD)
        server.send_message(msg)
        server.quit()
        
        print(f"‚úì Email envoy√© √† {NOTIF_EMAIL}")
        
    except Exception as e:
        print(f"‚ùå Erreur envoi email: {e}")

# =====================================================
# FONCTION PRINCIPALE
# =====================================================

def reveil_quotidien():
    """
    Fonction principale - Orchestration V2.9 avec nouveau cadre rapport
    """
    print("=" * 60)
    print(f"=== R√âVEIL {datetime.now().strftime('%d/%m/%Y %H:%M:%S')} ===")
    print("=" * 60)
    
    print("\n[1/6] R√©cup√©ration des donn√©es...")
    emails = fetch_emails()
    memoire_files = load_memoire_files()
    db_data = query_database()
    
    print("\n[2/6] Claude analyse et d√©cide (avec cadre rapport V2.9)...")
    resultat = claude_decide_et_execute(emails, memoire_files, db_data)
    
    if not resultat:
        print("\n‚ùå ERREUR: Pas de r√©sultat de Claude")
        send_email_rapport(f"""
# ‚ö†Ô∏è ERREUR DE R√âVEIL

Date: {datetime.now().strftime('%d/%m/%Y %H:%M')}

Le r√©veil a √©chou√© car Claude n'a pas retourn√© de r√©sultat valide.

V√©rifier les logs Render pour plus de d√©tails.
        """)
        return
    
    print("\n[3/6] Sauvegarde dans PostgreSQL...")
    save_to_database(resultat, emails)
    
    print("\n[4/6] √âcriture des fichiers m√©moire...")
    files_updated = save_memoire_files(resultat)
    
    print("\n[5/6] Commit vers GitHub...")
    if files_updated:
        commit_msg = f"üîÑ R√©veil automatique du {datetime.now().strftime('%d/%m/%Y √† %H:%M')}"
        git_commit_and_push(files_updated, commit_msg)
    else:
        print("‚ÑπÔ∏è Aucun fichier m√©moire √† commiter")
    
    print("\n[6/6] Envoi du rapport...")
    send_email_rapport(resultat.get('rapport_quotidien', 'Pas de rapport g√©n√©r√©'))
    
    print("\n" + "=" * 60)
    print("=== R√âVEIL TERMIN√â AVEC SUCC√àS ===")
    print("=" * 60)

# =====================================================
# SCHEDULER
# =====================================================

def keep_alive():
    """Fonction vide juste pour garder le service actif"""
    print(f"[{datetime.now().strftime('%H:%M:%S')}] Service actif - Prochain r√©veil programm√© √† 10h00 France")

# =====================================================
# POINT D'ENTR√âE
# =====================================================

if __name__ == "__main__":
    print("=" * 60)
    print("üîß _Head.Soeurise - Module 1 v2.9")
    print("Architecture : Nouveau Cadre Rapport Mature")
    print("R√©veil : 10h00 France (08:00 UTC)")
    print("NOUVEAU V2.9:")
    print("  - ‚úÖ Rapports factuels et critiques")
    print("  - ‚úÖ Auto-√©valuation obligatoire")
    print("  - ‚úÖ Suppression auto-c√©l√©bration excessive")
    print("  - ‚úÖ Rapports courts si faible activit√©")
    print("H√âRITE DE V2.8:")
    print("  - ‚úÖ Extraction PDF (pdfplumber)")
    print("  - ‚úÖ Analyse documents intelligente")
    print("=" * 60)
    print(f"‚úì Service d√©marr√© √† {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    if not PDF_SUPPORT:
        print("\n‚ö†Ô∏è ATTENTION: pdfplumber non install√©")
        print("   ‚Üí Installer avec: pip install pdfplumber --break-system-packages")
        print("   ‚Üí L'extraction PDF sera d√©sactiv√©e jusqu'√† installation")
    
    if not init_git_repo():
        print("\n‚ö†Ô∏è ATTENTION: √âchec initialisation Git")
        print("   ‚Üí Le service continuera mais sans persistence GitHub")
    
    sauvegarder_conversation_09_octobre()
    
    print("\n" + "=" * 60)
    print("üß™ R√âVEIL DE TEST AU D√âMARRAGE")
    print("=" * 60)
    try:
        reveil_quotidien()
    except Exception as e:
        print(f"\n‚ùå Erreur lors du r√©veil de test: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "=" * 60)
    schedule.every().day.at("08:00").do(reveil_quotidien)
    
    print(f"‚úì R√©veil quotidien programm√© √† 08:00 UTC = 10:00 France (√©t√©)")
    print(f"‚úì M√©moires charg√©es via API GitHub")
    print(f"‚úì R√©pertoire attachments: {ATTACHMENTS_DIR}")
    if PDF_SUPPORT:
        print(f"‚úì Analyse PDF : ACTIV√âE (pdfplumber disponible)")
    else:
        print(f"‚ö†Ô∏è Analyse PDF : D√âSACTIV√âE (pdfplumber requis)")
    print("=" * 60)
    
    schedule.every(30).minutes.do(keep_alive)
    
    print("\n‚è∞ En attente du prochain r√©veil programm√©...")
    print("   (Le service reste actif en permanence)\n")
    
    while True:
        schedule.run_pending()
        time.sleep(60)
